#!/bin/bash

echo "ðŸš€ ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
echo "================================"
echo ""

# ã‚«ãƒ©ãƒ¼å®šç¾©
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m'

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
WORK_DIR="/Users/0xhude/Desktop/mlbot"
cd $WORK_DIR

# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir -p logs/retraining
LOG_FILE="logs/retraining/retraining_$(date +%Y%m%d_%H%M%S).log"

# ãƒ­ã‚®ãƒ³ã‚°é–¢æ•°
log() {
    echo -e "$1" | tee -a $LOG_FILE
}

# ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
set -e
trap 'log "${RED}âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„: $LOG_FILE${NC}"' ERR

# ã‚¹ãƒ†ãƒƒãƒ—1: ç’°å¢ƒç¢ºèª
log "${BLUE}=== Step 1: ç’°å¢ƒç¢ºèª ===${NC}"
log "Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³:"
python3 --version | tee -a $LOG_FILE

log "\nå¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªç¢ºèª:"
python3 -c "import pandas, numpy, duckdb, tensorflow, xgboost, imblearn; print('âœ… ã™ã¹ã¦ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨å¯èƒ½')" 2>&1 | tee -a $LOG_FILE || {
    log "${RED}å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚requirements.txtã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚${NC}"
    exit 1
}

# ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ‡ãƒ¼ã‚¿çµ±åˆ
log "\n${BLUE}=== Step 2: å±¥æ­´ãƒ‡ãƒ¼ã‚¿ã®çµ±åˆ ===${NC}"
log "æ—¢å­˜ã®2-4å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆä¸­..."

python3 merge_historical_data.py 2>&1 | tee -a $LOG_FILE

if [ $? -eq 0 ]; then
    log "${GREEN}âœ… ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†${NC}"
else
    log "${RED}âŒ ãƒ‡ãƒ¼ã‚¿çµ±åˆã«å¤±æ•—ã—ã¾ã—ãŸ${NC}"
    exit 1
fi

# ã‚¹ãƒ†ãƒƒãƒ—3: ãƒãƒ©ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
log "\n${BLUE}=== Step 3: ãƒãƒ©ãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ ===${NC}"
log "52æ¬¡å…ƒã®ç‰¹å¾´é‡ã§ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆä¸­..."

python3 prepare_balanced_dataset_v2.py 2>&1 | tee -a $LOG_FILE

if [ $? -eq 0 ]; then
    log "${GREEN}âœ… ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆå®Œäº†${NC}"
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆã‚’è¡¨ç¤º
    python3 -c "
import numpy as np
import json

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
data = np.load('data/balanced_dataset_v4_full.npz')

# ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
with open('data/balanced_dataset_v4_full_metadata.json', 'r') as f:
    metadata = json.load(f)

print('')
print('ðŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ:')
print(f'  è¨“ç·´: {metadata[\"train_samples\"]:,}ä»¶ (Buy: {metadata[\"train_buy_ratio\"]*100:.1f}%)')
print(f'  æ¤œè¨¼: {metadata[\"val_samples\"]:,}ä»¶ (Buy: {metadata[\"val_buy_ratio\"]*100:.1f}%)')
print(f'  ãƒ†ã‚¹ãƒˆ: {metadata[\"test_samples\"]:,}ä»¶ (Buy: {metadata[\"test_buy_ratio\"]*100:.1f}%)')
print(f'  ç‰¹å¾´é‡: {metadata[\"n_features\"]}æ¬¡å…ƒ')
    " 2>&1 | tee -a $LOG_FILE
else
    log "${RED}âŒ ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ${NC}"
    exit 1
fi

# ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«è¨“ç·´
log "\n${BLUE}=== Step 4: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«è¨“ç·´ ===${NC}"
log "4ã¤ã®ãƒ¢ãƒ‡ãƒ«ï¼ˆLSTM, Transformer, XGBoost, NNï¼‰ã‚’è¨“ç·´ä¸­..."
log "${YELLOW}âš ï¸  ã“ã®å‡¦ç†ã«ã¯æ•°æ™‚é–“ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™${NC}"

# GPUã®ç¢ºèª
python3 -c "
import tensorflow as tf
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    print(f'ðŸŽ® GPUåˆ©ç”¨å¯èƒ½: {len(gpus)}å€‹ã®GPU')
else:
    print('ðŸ’» CPU mode')
" 2>&1 | tee -a $LOG_FILE

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Ÿè¡Œ
python3 train_ensemble_model.py 2>&1 | tee -a $LOG_FILE

if [ $? -eq 0 ]; then
    log "${GREEN}âœ… ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†${NC}"
    
    # è¨“ç·´çµæžœã®ç¢ºèª
    if [ -f "models/v4_ensemble/metadata.json" ]; then
        log "\nðŸ“Š è¨“ç·´çµæžœ:"
        python3 -c "
import json
with open('models/v4_ensemble/metadata.json', 'r') as f:
    metadata = json.load(f)
print(f'  ä½œæˆæ—¥æ™‚: {metadata[\"created_at\"]}')
print(f'  ãƒ¢ãƒ‡ãƒ«: {metadata[\"model_names\"]}')
print(f'  ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿: {metadata[\"ensemble_weights\"]}')
        " 2>&1 | tee -a $LOG_FILE
    fi
else
    log "${RED}âŒ ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã«å¤±æ•—ã—ã¾ã—ãŸ${NC}"
    exit 1
fi

# ã‚¹ãƒ†ãƒƒãƒ—5: ONNXå¤‰æ›ã®æº–å‚™
log "\n${BLUE}=== Step 5: ONNXå¤‰æ›æº–å‚™ ===${NC}"

# ONNXå¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆ
cat > convert_to_onnx_v4.py << 'EOF'
#!/usr/bin/env python3
"""
è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ONNXå½¢å¼ã«å¤‰æ›
"""

import tensorflow as tf
import tf2onnx
import onnx
import os
import json

def convert_keras_to_onnx(model_path, output_path, input_shape):
    """Kerasãƒ¢ãƒ‡ãƒ«ã‚’ONNXã«å¤‰æ›"""
    print(f"Converting {model_path} to ONNX...")
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    model = tf.keras.models.load_model(model_path, compile=False)
    
    # ONNXå¤‰æ›
    spec = (tf.TensorSpec((None, input_shape), tf.float32, name="float_input"),)
    
    model_proto, _ = tf2onnx.convert.from_keras(
        model, 
        input_signature=spec,
        output_path=output_path,
        opset=13
    )
    
    print(f"âœ… Converted to {output_path}")
    
    # æ¤œè¨¼
    onnx_model = onnx.load(output_path)
    onnx.checker.check_model(onnx_model)
    print("âœ… ONNX model validation passed")
    
    return output_path

def main():
    # 52æ¬¡å…ƒã®å…¥åŠ›
    input_shape = 52
    
    # å„ãƒ¢ãƒ‡ãƒ«ã‚’å¤‰æ›
    models_to_convert = [
        ('lstm', 'models/v4_ensemble/lstm_model.h5'),
        ('transformer', 'models/v4_ensemble/transformer_model.h5'),
        ('neural_net', 'models/v4_ensemble/neural_net_model.h5')
    ]
    
    converted_models = []
    
    for name, keras_path in models_to_convert:
        if os.path.exists(keras_path):
            onnx_path = keras_path.replace('.h5', '.onnx')
            try:
                convert_keras_to_onnx(keras_path, onnx_path, input_shape)
                converted_models.append(name)
            except Exception as e:
                print(f"âŒ Failed to convert {name}: {e}")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
    metadata_path = 'models/v4_ensemble/metadata.json'
    if os.path.exists(metadata_path):
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        metadata['onnx_models'] = converted_models
        metadata['input_shape'] = input_shape
        
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
    
    print(f"\nâœ… Conversion complete! Converted {len(converted_models)} models to ONNX")

if __name__ == "__main__":
    main()
EOF

log "ONNXå¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½œæˆã—ã¾ã—ãŸ"

# æœ€çµ‚ã‚µãƒžãƒªãƒ¼
log "\n${GREEN}=== è¨“ç·´å®Œäº†ã‚µãƒžãƒªãƒ¼ ===${NC}"
log "âœ… ãƒ‡ãƒ¼ã‚¿çµ±åˆ: 2-4å¹´åˆ†ã®å±¥æ­´ãƒ‡ãƒ¼ã‚¿ï¼ˆ660ä¸‡ãƒ¬ã‚³ãƒ¼ãƒ‰ï¼‰"
log "âœ… ç‰¹å¾´é‡: 52æ¬¡å…ƒï¼ˆæ—¢å­˜44 + æ–°è¦8ï¼‰"
log "âœ… ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°: Buy/Sellæ¯”çŽ‡ã‚’40-60%ã«èª¿æ•´"
log "âœ… ãƒ¢ãƒ‡ãƒ«: LSTM, Transformer, XGBoost, Neural Networkã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«"
log ""
log "ðŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:"
log "  - data/balanced_dataset_v4_full.npz"
log "  - models/v4_ensemble/"
log ""
log "${YELLOW}æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:${NC}"
log "1. python3 convert_to_onnx_v4.py ã§ONNXå¤‰æ›"
log "2. A/Bãƒ†ã‚¹ãƒˆã®å®Ÿæ–½"
log "3. æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤"
log ""
log "è©³ç´°ãƒ­ã‚°: $LOG_FILE"
log "${GREEN}âœ… ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†ï¼${NC}"