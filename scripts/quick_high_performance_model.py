#!/usr/bin/env python3
"""
é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®é«˜é€Ÿè¨“ç·´ç‰ˆï¼ˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ¶é™ã—ã¦è¿…é€Ÿãªçµæœã‚’å¾—ã‚‹ï¼‰
35å€‹ã®å®Ÿè¨¼æ¸ˆã¿ç‰¹å¾´é‡ã‚’ä½¿ç”¨
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import duckdb
from typing import Dict, List, Tuple
import joblib
from sklearn.ensemble import RandomForestClassifier, VotingClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import TimeSeriesSplit, cross_val_score
from sklearn.metrics import classification_report, roc_auc_score, precision_score, recall_score
import lightgbm as lgb
import catboost as cb
import warnings
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class QuickHighPerformanceModel:
    """é«˜é€Ÿé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
    
    def __init__(self, profit_threshold: float = 0.005):
        self.profit_threshold = profit_threshold
        self.scaler = StandardScaler()
        self.models = {}
        self.feature_names = []
        
    def load_sample_data(self, symbol: str = "BTCUSDT", limit: int = 20000) -> pd.DataFrame:
        """ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆé«˜é€ŸåŒ–ã®ãŸã‚åˆ¶é™ï¼‰"""
        print(f"ğŸ“Š {symbol}ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­ï¼ˆæœ€å¤§{limit:,}ä»¶ï¼‰...")
        
        try:
            conn = duckdb.connect("data/historical_data.duckdb", read_only=True)
            
            query = f"""
            SELECT 
                timestamp,
                open,
                high,
                low,
                close,
                volume
            FROM klines_{symbol.lower()}
            WHERE timestamp >= '2024-03-01'
            ORDER BY timestamp DESC
            LIMIT {limit}
            """
            
            data = conn.execute(query).df()
            data['timestamp'] = pd.to_datetime(data['timestamp'])
            data.set_index('timestamp', inplace=True)
            data.sort_index(inplace=True)  # æ™‚ç³»åˆ—é †ã«ä¸¦ã¹ç›´ã—
            
            conn.close()
            print(f"âœ… {len(data):,}ä»¶ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’èª­ã¿è¾¼ã¿å®Œäº†")
            
            return data
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()

    def create_essential_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """å¿…é ˆã®35å€‹ã®é«˜å“è³ªç‰¹å¾´é‡ã‚’ç”Ÿæˆ"""
        print("ğŸ”§ 35å€‹ã®å®Ÿè¨¼æ¸ˆã¿ç‰¹å¾´é‡ã‚’ç”Ÿæˆä¸­...")
        
        df = data.copy()
        
        # åŸºæœ¬ä¾¡æ ¼ç‰¹å¾´é‡ (4å€‹)
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        df['hl_ratio'] = (df['high'] - df['low']) / df['close']
        df['oc_ratio'] = (df['close'] - df['open']) / df['open']
        
        # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ãƒªã‚¿ãƒ¼ãƒ³ (6å€‹)
        for period in [1, 3, 5, 10, 15, 30]:
            df[f'return_{period}'] = df['close'].pct_change(period)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ (4å€‹)
        for window in [5, 10, 20, 30]:
            df[f'vol_{window}'] = df['returns'].rolling(window).std()
        
        # ç§»å‹•å¹³å‡ã¨ä¾¡æ ¼æ¯”è¼ƒ (6å€‹)
        for ma in [5, 10, 20]:
            df[f'sma_{ma}'] = df['close'].rolling(ma).mean()
            df[f'price_vs_sma_{ma}'] = (df['close'] - df[f'sma_{ma}']) / df[f'sma_{ma}']
        
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ æŒ‡æ¨™ (3å€‹)
        df['momentum_3'] = df['close'].pct_change(3)
        df['momentum_5'] = df['close'].pct_change(5)
        df['momentum_10'] = df['close'].pct_change(10)
        
        # ãƒœãƒªãƒ¥ãƒ¼ãƒ ç‰¹å¾´é‡ (3å€‹)
        df['volume_ma'] = df['volume'].rolling(20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_ma']
        df['log_volume'] = np.log(df['volume'] + 1)
        
        # RSI (1å€‹)
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / (loss + 1e-8)
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰ä½ç½® (1å€‹)
        bb_middle = df['close'].rolling(20).mean()
        bb_std = df['close'].rolling(20).std()
        bb_upper = bb_middle + (bb_std * 2)
        bb_lower = bb_middle - (bb_std * 2)
        df['bb_position'] = (df['close'] - bb_lower) / (bb_upper - bb_lower + 1e-8)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ¨™ (2å€‹)
        df['trend_strength'] = (df['sma_5'] - df['sma_20']) / df['sma_20']
        df['price_above_ma'] = (df['close'] > df['sma_20']).astype(int)
        
        # ãƒœãƒªãƒ¥ãƒ¼ãƒ -ä¾¡æ ¼ç›¸äº’ä½œç”¨ (1å€‹)
        df['volume_price_change'] = df['volume_ratio'] * abs(df['returns'])
        
        # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ  (2å€‹)
        df['high_vol'] = (df['vol_20'] > df['vol_20'].rolling(50).quantile(0.8)).astype(int)
        df['low_vol'] = (df['vol_20'] < df['vol_20'].rolling(50).quantile(0.2)).astype(int)
        
        # æ™‚é–“ç‰¹å¾´é‡ (2å€‹)
        df['hour'] = df.index.hour
        df['day_of_week'] = df.index.dayofweek
        
        # åˆè¨ˆ35å€‹ã®ç‰¹å¾´é‡
        feature_cols = [
            'returns', 'log_returns', 'hl_ratio', 'oc_ratio',
            'return_1', 'return_3', 'return_5', 'return_10', 'return_15', 'return_30',
            'vol_5', 'vol_10', 'vol_20', 'vol_30',
            'sma_5', 'sma_10', 'sma_20',
            'price_vs_sma_5', 'price_vs_sma_10', 'price_vs_sma_20',
            'momentum_3', 'momentum_5', 'momentum_10',
            'volume_ma', 'volume_ratio', 'log_volume',
            'rsi', 'bb_position',
            'trend_strength', 'price_above_ma',
            'volume_price_change',
            'high_vol', 'low_vol',
            'hour', 'day_of_week'
        ]
        
        self.feature_names = feature_cols
        print(f"âœ… {len(feature_cols)}å€‹ã®å®Ÿè¨¼æ¸ˆã¿ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†")
        
        return df

    def create_profit_labels(self, data: pd.DataFrame, horizon: int = 5) -> pd.Series:
        """åç›Šãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆ"""
        print(f"ğŸ¯ {horizon}åˆ†å¾Œã®åç›Šãƒ©ãƒ™ãƒ«ã‚’ç”Ÿæˆä¸­...")
        
        transaction_cost = 0.0012  # 0.12%
        
        future_return = data['close'].pct_change(horizon).shift(-horizon)
        long_profit = future_return - transaction_cost
        short_profit = -future_return - transaction_cost
        
        profitable = ((long_profit > self.profit_threshold) | 
                     (short_profit > self.profit_threshold)).astype(int)
        
        print(f"âœ… åç›Šãƒ©ãƒ™ãƒ«ç”Ÿæˆå®Œäº† (é™½æ€§ç‡: {profitable.mean():.2%})")
        return profitable

    def prepare_training_data(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™"""
        print("ğŸ—‚ï¸ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ä¸­...")
        
        y = self.create_profit_labels(data)
        X = data[self.feature_names].copy()
        
        # æœ‰åŠ¹ãªã‚µãƒ³ãƒ—ãƒ«ã®ã¿ä½¿ç”¨
        valid_mask = ~(X.isnull().any(axis=1) | y.isnull())
        X = X[valid_mask]
        y = y[valid_mask]
        
        # æ®‹ã‚Šã®NaNã‚’å‡¦ç†
        for col in X.columns:
            if X[col].dtype in ['float64', 'int64']:
                X[col] = X[col].fillna(X[col].median())
            else:
                X[col] = X[col].fillna(0)
        
        print(f"âœ… è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†")
        print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X):,}")
        print(f"   ç‰¹å¾´é‡æ•°: {len(X.columns)}")
        print(f"   é™½æ€§ç‡: {y.mean():.2%}")
        
        return X, y

    def train_quick_models(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        print("ğŸ¤– é«˜é€Ÿãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...")
        
        # é«˜é€Ÿè¨­å®šã®ãƒ¢ãƒ‡ãƒ«
        models = {
            'random_forest': RandomForestClassifier(
                n_estimators=50,  # é«˜é€ŸåŒ–ã®ãŸã‚å‰Šæ¸›
                max_depth=8,
                min_samples_split=20,
                class_weight='balanced',
                random_state=42,
                n_jobs=-1
            ),
            'lightgbm': lgb.LGBMClassifier(
                n_estimators=100,  # é«˜é€ŸåŒ–ã®ãŸã‚å‰Šæ¸›
                learning_rate=0.1,
                max_depth=5,
                num_leaves=20,
                class_weight='balanced',
                random_state=42,
                n_jobs=-1,
                verbose=-1
            )
        }
        
        cv_results = {}
        tscv = TimeSeriesSplit(n_splits=2)  # é«˜é€ŸåŒ–ã®ãŸã‚å‰Šæ¸›
        
        for name, model in models.items():
            print(f"ğŸ”„ {name}ã‚’è¨“ç·´ä¸­...")
            
            # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
            cv_scores = cross_val_score(model, X, y, cv=tscv, scoring='roc_auc', n_jobs=-1)
            
            # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            model.fit(X, y)
            self.models[name] = model
            
            cv_results[name] = {
                'auc_mean': cv_scores.mean(),
                'auc_std': cv_scores.std()
            }
            
            print(f"   AUC: {cv_results[name]['auc_mean']:.3f}Â±{cv_results[name]['auc_std']:.3f}")
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä½œæˆ
        print("ğŸ”„ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä½œæˆä¸­...")
        ensemble_models = [(name, model) for name, model in self.models.items()]
        ensemble = VotingClassifier(estimators=ensemble_models, voting='soft')
        ensemble.fit(X, y)
        self.models['ensemble'] = ensemble
        
        ensemble_cv_scores = cross_val_score(ensemble, X, y, cv=tscv, scoring='roc_auc', n_jobs=-1)
        cv_results['ensemble'] = {
            'auc_mean': ensemble_cv_scores.mean(),
            'auc_std': ensemble_cv_scores.std()
        }
        
        print(f"   ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«AUC: {cv_results['ensemble']['auc_mean']:.3f}Â±{cv_results['ensemble']['auc_std']:.3f}")
        
        return cv_results

    def evaluate_trading_performance(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """å–å¼•æ€§èƒ½ã‚’è©•ä¾¡"""
        print("ğŸ“ˆ å–å¼•æ€§èƒ½è©•ä¾¡ä¸­...")
        
        # æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
        best_model_name = 'ensemble'
        best_model = self.models[best_model_name]
        
        y_proba = best_model.predict_proba(X)[:, 1]
        
        results = {}
        for threshold in [0.5, 0.6, 0.7, 0.8, 0.9]:
            signals = (y_proba > threshold)
            
            if signals.sum() > 0:
                signal_accuracy = y[signals].mean()
                signal_count = signals.sum()
                
                # å–å¼•æ€§èƒ½è¨ˆç®—
                expected_return_per_trade = 0.008  # 0.8%æœŸå¾…
                transaction_cost = 0.0012
                net_return_per_trade = signal_accuracy * expected_return_per_trade - transaction_cost
                
                results[threshold] = {
                    'signal_count': int(signal_count),
                    'accuracy': float(signal_accuracy),
                    'net_return_per_trade': float(net_return_per_trade),
                    'daily_signals': int(signal_count / (len(X) / (24*12))),  # 1æ—¥ã‚ãŸã‚Š
                }
            else:
                results[threshold] = {
                    'signal_count': 0,
                    'accuracy': 0,
                    'net_return_per_trade': 0,
                    'daily_signals': 0
                }
        
        return results

    def save_model(self, cv_results: Dict, model_dir: str = "models/quick_high_performance"):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        model_path = Path(model_dir)
        model_path.mkdir(parents=True, exist_ok=True)
        
        # æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®ã¿ä¿å­˜
        best_model_name = max(cv_results.keys(), key=lambda k: cv_results[k]['auc_mean'])
        best_model = self.models[best_model_name]
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        model_file = model_path / f"{best_model_name}_model.pkl"
        joblib.dump(best_model, model_file)
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä¿å­˜
        scaler_file = model_path / "scaler.pkl"
        joblib.dump(self.scaler, scaler_file)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        import json
        from datetime import datetime
        
        metadata = {
            "model_type": "quick_high_performance",
            "feature_count": len(self.feature_names),
            "feature_names": self.feature_names,
            "training_date": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "model_version": "3.0_quick",
            "best_model": best_model_name,
            "performance": cv_results,
            "config": {
                "profit_threshold": self.profit_threshold,
                "transaction_cost": 0.0012,
                "horizon": 5
            }
        }
        
        metadata_file = model_path / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_path}")
        return metadata


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("="*70)
    print("ğŸš€ é«˜é€Ÿé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«è¨“ç·´")
    print("="*70)
    
    model = QuickHighPerformanceModel(profit_threshold=0.005)
    
    # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data = model.load_sample_data(limit=20000)
    if len(data) < 1000:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
        return
    
    # 2. ç‰¹å¾´é‡ç”Ÿæˆ
    data_with_features = model.create_essential_features(data)
    
    # 3. è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™
    X, y = model.prepare_training_data(data_with_features)
    if len(X) < 100:
        print("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
        return
    
    # 4. ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    cv_results = model.train_quick_models(X, y)
    
    # 5. å–å¼•æ€§èƒ½è©•ä¾¡
    trading_results = model.evaluate_trading_performance(X, y)
    
    # 6. ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    metadata = model.save_model(cv_results)
    
    # çµæœè¡¨ç¤º
    print("\n" + "="*70)
    print("ğŸ“Š é«˜é€Ÿé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«çµæœ")
    print("="*70)
    
    print(f"\nğŸ”¢ ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X):,}")
    print(f"   ç‰¹å¾´é‡æ•°: {len(X.columns)}")
    print(f"   é™½æ€§ç‡: {y.mean():.2%}")
    
    print(f"\nğŸ¯ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
    for model_name, scores in cv_results.items():
        status = "ğŸ†" if scores['auc_mean'] == max(s['auc_mean'] for s in cv_results.values()) else "  "
        print(f"   {status} {model_name.upper():15}: AUC = {scores['auc_mean']:.3f}Â±{scores['auc_std']:.3f}")
    
    best_auc = max(cv_results[k]['auc_mean'] for k in cv_results.keys())
    
    print(f"\nğŸ“ˆ å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³:")
    for threshold, result in trading_results.items():
        if result['signal_count'] > 0:
            print(f"   é–¾å€¤ {threshold}: {result['signal_count']}å›å–å¼•, "
                  f"ç²¾åº¦ {result['accuracy']:.1%}, "
                  f"1æ—¥ {result['daily_signals']}å›")
    
    # æ€§èƒ½è©•ä¾¡
    if best_auc >= 0.75:
        print(f"\nâœ… å„ªç§€ãªæ€§èƒ½ (AUC {best_auc:.3f}) - å®Ÿç”¨å¯èƒ½")
        recommendation = "ãƒ‡ãƒ—ãƒ­ã‚¤æ¨å¥¨"
    elif best_auc >= 0.65:
        print(f"\nğŸŸ¨ è‰¯å¥½ãªæ€§èƒ½ (AUC {best_auc:.3f}) - æœ€é©åŒ–æ¨å¥¨")
        recommendation = "ã•ã‚‰ãªã‚‹æ”¹å–„ã‚’æ¤œè¨"
    else:
        print(f"\nâŒ æ€§èƒ½ä¸è¶³ (AUC {best_auc:.3f}) - å†è¨­è¨ˆå¿…è¦")
        recommendation = "ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’è¦‹ç›´ã—"
    
    print(f"\nğŸ¯ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {recommendation}")
    print(f"ğŸ’¾ ä¿å­˜å ´æ‰€: models/quick_high_performance/")
    
    return model, cv_results, trading_results


if __name__ == "__main__":
    model, cv_results, trading_results = main()