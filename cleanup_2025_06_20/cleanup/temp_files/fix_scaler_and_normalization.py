#!/usr/bin/env python3
"""
ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼å•é¡Œã‚’è§£æ±ºã—ã€é©åˆ‡ãªç‰¹å¾´é‡æ­£è¦åŒ–ã‚’å®Ÿè£…
"""
import sys
sys.path.insert(0, '/home/ubuntu/mlbot')

import os
import json
import numpy as np
import pickle
from pathlib import Path
from src.common.config import settings
from src.common.logging import get_logger
from src.common.discord_notifier import discord_notifier

logger = get_logger(__name__)

def investigate_scaler_file():
    """ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°èª¿æŸ»"""
    
    logger.info("ğŸ” ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«èª¿æŸ»é–‹å§‹...")
    
    scaler_paths = [
        "models/v3.1_improved/scaler.pkl",
        "models/v1.0/scaler.pkl", 
        "models/v2.0/scaler.pkl",
        "models/scaler.pkl",
        "models/fast_nn_scaler.pkl"
    ]
    
    investigation_results = {}
    
    for scaler_path in scaler_paths:
        if os.path.exists(scaler_path):
            logger.info(f"ğŸ“ {scaler_path} å­˜åœ¨ç¢ºèª")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºç¢ºèª
            file_size = os.path.getsize(scaler_path)
            logger.info(f"  ã‚µã‚¤ã‚º: {file_size} bytes")
            
            # Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³é•ã„ã§ã®ãƒ­ãƒ¼ãƒ‰è©¦è¡Œ
            try:
                # é€šå¸¸ã®ãƒ­ãƒ¼ãƒ‰
                with open(scaler_path, 'rb') as f:
                    scaler = pickle.load(f)
                logger.info(f"  âœ… é€šå¸¸ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {type(scaler)}")
                investigation_results[scaler_path] = {"success": True, "type": str(type(scaler))}
                
            except Exception as e1:
                logger.error(f"  âŒ é€šå¸¸ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e1}")
                
                try:
                    # encodingæŒ‡å®šã§ãƒ­ãƒ¼ãƒ‰
                    with open(scaler_path, 'rb') as f:
                        scaler = pickle.load(f, encoding='latin1')
                    logger.info(f"  âœ… Latin-1ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {type(scaler)}")
                    investigation_results[scaler_path] = {"success": True, "type": str(type(scaler)), "encoding": "latin1"}
                    
                except Exception as e2:
                    logger.error(f"  âŒ Latin-1ãƒ­ãƒ¼ãƒ‰ã‚‚å¤±æ•—: {e2}")
                    
                    try:
                        # protocolé•ã„ã§ãƒ­ãƒ¼ãƒ‰
                        import pickle5 as pickle
                        with open(scaler_path, 'rb') as f:
                            scaler = pickle.load(f)
                        logger.info(f"  âœ… Pickle5ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {type(scaler)}")
                        investigation_results[scaler_path] = {"success": True, "type": str(type(scaler)), "method": "pickle5"}
                        
                    except Exception as e3:
                        logger.error(f"  âŒ å…¨ã¦ã®ãƒ­ãƒ¼ãƒ‰æ–¹æ³•å¤±æ•—")
                        investigation_results[scaler_path] = {"success": False, "errors": [str(e1), str(e2), str(e3)]}
    
    return investigation_results

def compute_feature_statistics(features_list):
    """ç‰¹å¾´é‡ã®çµ±è¨ˆå€¤ï¼ˆå¹³å‡ãƒ»æ¨™æº–åå·®ï¼‰ã‚’è¨ˆç®—"""
    
    if not features_list:
        return None, None
    
    # å„ç‰¹å¾´é‡ã®å€¤ã‚’åé›†
    feature_arrays = []
    for features in features_list:
        if isinstance(features, dict):
            feature_arrays.append(list(features.values()))
        else:
            feature_arrays.append(features)
    
    # numpyé…åˆ—ã«å¤‰æ›
    feature_matrix = np.array(feature_arrays, dtype=np.float32)
    
    # çµ±è¨ˆå€¤è¨ˆç®—
    mean = np.mean(feature_matrix, axis=0)
    std = np.std(feature_matrix, axis=0)
    
    # ã‚¼ãƒ­é™¤ç®—é˜²æ­¢
    std = np.where(std == 0, 1.0, std)
    
    return mean, std

def create_manual_scaler():
    """44æ¬¡å…ƒãƒ¢ãƒ‡ãƒ«ç”¨ã®æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½œæˆ"""
    
    logger.info("ğŸ”§ æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½œæˆé–‹å§‹...")
    
    # 44å€‹ã®ç‰¹å¾´é‡ã«å¯¾ã™ã‚‹å…¸å‹çš„ãªçµ±è¨ˆå€¤ã‚’å®šç¾©
    # ã“ã‚Œã‚‰ã¯é‡‘èãƒ‡ãƒ¼ã‚¿ã®ä¸€èˆ¬çš„ãªç¯„å›²ã«åŸºã¥ã
    feature_stats = {
        # ãƒªã‚¿ãƒ¼ãƒ³ç³»ï¼ˆé€šå¸¸ã¯å°ã•ã„å€¤ï¼‰
        "returns": {"mean": 0.0, "std": 0.01},
        "log_returns": {"mean": 0.0, "std": 0.01},
        "hl_ratio": {"mean": 0.02, "std": 0.01},
        "oc_ratio": {"mean": 0.0, "std": 0.005},
        "return_1": {"mean": 0.0, "std": 0.01},
        "return_3": {"mean": 0.0, "std": 0.015},
        "return_5": {"mean": 0.0, "std": 0.02},
        "return_10": {"mean": 0.0, "std": 0.025},
        "return_20": {"mean": 0.0, "std": 0.03},
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»
        "vol_5": {"mean": 0.015, "std": 0.01},
        "vol_10": {"mean": 0.018, "std": 0.012},
        "vol_20": {"mean": 0.02, "std": 0.015},
        "vol_30": {"mean": 0.022, "std": 0.018},
        "vol_ratio_10": {"mean": 1.1, "std": 0.2},
        "vol_ratio_20": {"mean": 1.15, "std": 0.25},
        
        # ä¾¡æ ¼vsç§»å‹•å¹³å‡ç³»ï¼ˆ1.0ä»˜è¿‘ï¼‰
        "price_vs_sma_5": {"mean": 1.0, "std": 0.02},
        "price_vs_sma_10": {"mean": 1.0, "std": 0.03},
        "price_vs_sma_20": {"mean": 1.0, "std": 0.04},
        "price_vs_sma_30": {"mean": 1.0, "std": 0.05},
        "price_vs_ema_5": {"mean": 1.0, "std": 0.02},
        "price_vs_ema_12": {"mean": 1.0, "std": 0.03},
        
        # MACDç³»
        "macd": {"mean": 0.0, "std": 0.1},
        "macd_hist": {"mean": 0.0, "std": 0.05},
        
        # RSIç³»ï¼ˆ20-80ã®ç¯„å›²ï¼‰
        "rsi_14": {"mean": 50.0, "std": 15.0},
        "rsi_21": {"mean": 50.0, "std": 15.0},
        
        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
        "bb_position_20": {"mean": 0.0, "std": 1.0},
        "bb_width_20": {"mean": 0.04, "std": 0.02},
        
        # ãƒœãƒªãƒ¥ãƒ¼ãƒ ç³»
        "volume_ratio_10": {"mean": 1.0, "std": 0.5},
        "volume_ratio_20": {"mean": 1.0, "std": 0.5},
        "log_volume": {"mean": 10.0, "std": 2.0},
        "volume_price_trend": {"mean": 0.0, "std": 0.1},
        
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
        "momentum_3": {"mean": 0.0, "std": 0.02},
        "momentum_5": {"mean": 0.0, "std": 0.025},
        "momentum_10": {"mean": 0.0, "std": 0.03},
        
        # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ï¼ˆ0-1ï¼‰
        "price_percentile_20": {"mean": 0.5, "std": 0.3},
        "price_percentile_50": {"mean": 0.5, "std": 0.3},
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦
        "trend_strength_short": {"mean": 0.1, "std": 0.1},
        "trend_strength_long": {"mean": 0.08, "std": 0.08},
        
        # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ ï¼ˆãƒã‚¤ãƒŠãƒªï¼‰
        "high_vol_regime": {"mean": 0.2, "std": 0.4},
        "low_vol_regime": {"mean": 0.8, "std": 0.4},
        "trending_market": {"mean": 0.3, "std": 0.45},
        
        # æ™‚é–“ç‰¹å¾´é‡
        "hour_sin": {"mean": 0.0, "std": 0.7},
        "hour_cos": {"mean": 0.0, "std": 0.7},
        "is_weekend": {"mean": 0.28, "std": 0.45}
    }
    
    # é…åˆ—å½¢å¼ã«å¤‰æ›ï¼ˆ44å€‹ã®ç‰¹å¾´é‡é †åºé€šã‚Šï¼‰
    feature_names = [
        "returns", "log_returns", "hl_ratio", "oc_ratio", "return_1",
        "return_3", "return_5", "return_10", "return_20", "vol_5",
        "vol_10", "vol_20", "vol_30", "vol_ratio_10", "vol_ratio_20",
        "price_vs_sma_5", "price_vs_sma_10", "price_vs_sma_20", "price_vs_sma_30", "price_vs_ema_5",
        "price_vs_ema_12", "macd", "macd_hist", "rsi_14", "rsi_21",
        "bb_position_20", "bb_width_20", "volume_ratio_10", "volume_ratio_20", "log_volume",
        "volume_price_trend", "momentum_3", "momentum_5", "momentum_10", "price_percentile_20",
        "price_percentile_50", "trend_strength_short", "trend_strength_long", "high_vol_regime", "low_vol_regime",
        "trending_market", "hour_sin", "hour_cos", "is_weekend"
    ]
    
    means = np.array([feature_stats[name]["mean"] for name in feature_names], dtype=np.float32)
    stds = np.array([feature_stats[name]["std"] for name in feature_names], dtype=np.float32)
    
    return means, stds, feature_names

def normalize_features(features_array, means, stds):
    """ç‰¹å¾´é‡ã‚’æ­£è¦åŒ–ï¼ˆæ¨™æº–åŒ–ï¼‰"""
    
    # (x - mean) / std
    normalized = (features_array - means) / stds
    
    # æ¥µç«¯ãªå€¤ã‚’ã‚¯ãƒªãƒƒãƒ—ï¼ˆ-5ã‹ã‚‰5ã®ç¯„å›²ï¼‰
    normalized = np.clip(normalized, -5, 5)
    
    return normalized

def save_manual_scaler(means, stds, feature_names):
    """æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜"""
    
    scaler_data = {
        "type": "manual_standard_scaler",
        "means": means.tolist(),
        "stds": stds.tolist(),
        "feature_names": feature_names,
        "n_features": len(feature_names),
        "created_at": "2025-06-16",
        "purpose": "44-dimension model normalization"
    }
    
    # JSONå½¢å¼ã§ä¿å­˜ï¼ˆpickleã®å•é¡Œã‚’å›é¿ï¼‰
    scaler_path = Path("models/v3.1_improved/manual_scaler.json")
    with open(scaler_path, 'w') as f:
        json.dump(scaler_data, f, indent=2)
    
    logger.info(f"âœ… æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜: {scaler_path}")
    
    return scaler_path

def test_normalization():
    """æ­£è¦åŒ–ã®ãƒ†ã‚¹ãƒˆ"""
    
    logger.info("ğŸ§ª æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆé–‹å§‹...")
    
    discord_notifier.send_system_status(
        "normalization_test",
        "ğŸ”§ **æ­£è¦åŒ–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆé–‹å§‹** ğŸ”§\n\n" +
        "ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼å•é¡Œã®å®Œå…¨è§£æ±ºä¸­..."
    )
    
    try:
        # 1. Pickleãƒ•ã‚¡ã‚¤ãƒ«èª¿æŸ»
        pickle_results = investigate_scaler_file()
        logger.info(f"ğŸ“‹ Pickleèª¿æŸ»çµæœ: {pickle_results}")
        
        # 2. æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½œæˆ
        means, stds, feature_names = create_manual_scaler()
        logger.info(f"âœ… æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½œæˆå®Œäº†: {len(feature_names)}ç‰¹å¾´é‡")
        
        # 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§æ¤œè¨¼
        # ãƒ©ãƒ³ãƒ€ãƒ ãª44æ¬¡å…ƒç‰¹å¾´é‡ã‚’ç”Ÿæˆ
        test_features = np.random.normal(0, 0.1, 44).astype(np.float32)
        logger.info(f"ğŸ§ª ãƒ†ã‚¹ãƒˆç‰¹å¾´é‡ç”Ÿæˆ: {test_features[:5]}")
        
        # æ­£è¦åŒ–é©ç”¨
        normalized_features = normalize_features(test_features, means, stds)
        logger.info(f"âœ… æ­£è¦åŒ–å¾Œ: {normalized_features[:5]}")
        
        # 4. å®Ÿéš›ã®ç‰¹å¾´é‡ã§ãƒ†ã‚¹ãƒˆï¼ˆä¾‹ã¨ã—ã¦ç°¡å˜ãªå€¤ï¼‰
        real_test = np.array([
            0.001,  # returns
            0.001,  # log_returns
            0.02,   # hl_ratio
            0.0005, # oc_ratio
            0.001,  # return_1
        ] + [0.0] * 39, dtype=np.float32)  # æ®‹ã‚Šã¯0
        
        normalized_real = normalize_features(real_test, means, stds)
        logger.info(f"ğŸ¯ å®Ÿãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆ:")
        logger.info(f"  å…¥åŠ›: {real_test[:5]}")
        logger.info(f"  æ­£è¦åŒ–å¾Œ: {normalized_real[:5]}")
        
        # 5. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä¿å­˜
        scaler_path = save_manual_scaler(means, stds, feature_names)
        
        # 6. å ±å‘Šæ›¸ç”Ÿæˆ
        report = "ğŸ”§ **æ­£è¦åŒ–ã‚·ã‚¹ãƒ†ãƒ ä¿®æ­£å®Œäº†** ğŸ”§\n\n"
        
        # Pickleèª¿æŸ»çµæœ
        pickle_success = any(result.get("success", False) for result in pickle_results.values())
        if pickle_success:
            report += "ğŸ“ **Pickleãƒ•ã‚¡ã‚¤ãƒ«**: ä¸€éƒ¨èª­ã¿è¾¼ã¿å¯èƒ½\n"
        else:
            report += "ğŸ“ **Pickleãƒ•ã‚¡ã‚¤ãƒ«**: å…¨ã¦ç ´æ\n"
        
        report += f"\nâœ… **æ‰‹å‹•ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä½œæˆ**:\n"
        report += f"â€¢ ç‰¹å¾´é‡æ•°: {len(feature_names)}\n"
        report += f"â€¢ é‡‘èãƒ‡ãƒ¼ã‚¿ç”¨çµ±è¨ˆå€¤è¨­å®š\n"
        report += f"â€¢ JSONå½¢å¼ã§ä¿å­˜ï¼ˆpickleå›é¿ï¼‰\n"
        
        report += f"\nğŸ§ª **æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆ**:\n"
        report += f"â€¢ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: æˆåŠŸ\n"
        report += f"â€¢ å®Ÿãƒ‡ãƒ¼ã‚¿æƒ³å®š: æˆåŠŸ\n"
        report += f"â€¢ å€¤ç¯„å›²: [-5, 5]ã«ã‚¯ãƒªãƒƒãƒ—\n"
        
        report += f"\nğŸš€ **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**:\n"
        report += f"æ­£è¦åŒ–ã‚’çµ±åˆã—ãŸæœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£…"
        
        discord_notifier.send_system_status("normalization_complete", report)
        
        return {
            "pickle_investigation": pickle_results,
            "manual_scaler_created": True,
            "scaler_path": str(scaler_path),
            "test_success": True
        }
        
    except Exception as e:
        logger.error(f"âŒ æ­£è¦åŒ–ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        discord_notifier.send_error("normalization_test", f"ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    logger.info("Starting scaler fix and normalization")
    result = test_normalization()
    logger.info(f"Normalization complete: {result}")