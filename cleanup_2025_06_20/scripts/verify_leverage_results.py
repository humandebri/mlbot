#!/usr/bin/env python3
"""
Verify the leverage backtest results and check for issues.
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import duckdb
import torch
import joblib
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.common.logging import get_logger, setup_logging

setup_logging()
logger = get_logger(__name__)

# Import the FastNN model
from scripts.fast_nn_model import FastNN

# Set device
device = torch.device("cuda" if torch.cuda.is_available() else "mps" if torch.backends.mps.is_available() else "cpu")


class VerifyLeverageResults:
    """Verify leverage backtest results for data integrity."""
    
    def __init__(self):
        self.scaler = None
        self.model = None
        self.device = device
        
    def load_model(self):
        """Load trained neural network model."""
        
        # Load scaler
        self.scaler = joblib.load("models/fast_nn_scaler.pkl")
        
        # Load model
        self.model = FastNN(input_dim=26, hidden_dim=64, dropout=0.3).to(self.device)
        self.model.load_state_dict(torch.load("models/fast_nn_final.pth"))
        self.model.eval()
        
        logger.info("Loaded neural network model for verification")
    
    def load_test_data(self) -> pd.DataFrame:
        """Load test data and verify it's real."""
        
        conn = duckdb.connect("data/historical_data.duckdb")
        
        # Check data statistics
        stats_query = """
        SELECT 
            COUNT(*) as total_records,
            MIN(timestamp) as min_date,
            MAX(timestamp) as max_date,
            AVG(close) as avg_price,
            STDDEV(close) as std_price,
            MIN(close) as min_price,
            MAX(close) as max_price
        FROM klines_btcusdt
        WHERE timestamp >= '2024-05-01' AND timestamp <= '2024-07-31'
        """
        
        stats = conn.execute(stats_query).df()
        print("\nğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆæƒ…å ±:")
        print(f"  ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats['total_records'].iloc[0]:,}")
        print(f"  æœŸé–“: {stats['min_date'].iloc[0]} - {stats['max_date'].iloc[0]}")
        print(f"  å¹³å‡ä¾¡æ ¼: ${stats['avg_price'].iloc[0]:,.2f}")
        print(f"  ä¾¡æ ¼æ¨™æº–åå·®: ${stats['std_price'].iloc[0]:,.2f}")
        print(f"  æœ€ä½ä¾¡æ ¼: ${stats['min_price'].iloc[0]:,.2f}")
        print(f"  æœ€é«˜ä¾¡æ ¼: ${stats['max_price'].iloc[0]:,.2f}")
        
        # Load actual data
        query = """
        SELECT timestamp, open, high, low, close, volume
        FROM klines_btcusdt
        WHERE timestamp >= '2024-05-01' AND timestamp <= '2024-07-31'
        ORDER BY timestamp
        """
        
        data = conn.execute(query).df()
        data['timestamp'] = pd.to_datetime(data['timestamp'])
        data.set_index('timestamp', inplace=True)
        conn.close()
        
        # Check for data anomalies
        print("\nğŸ” ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯:")
        
        # Check for gaps
        time_diffs = data.index.to_series().diff()
        max_gap = time_diffs.max()
        print(f"  æœ€å¤§æ™‚é–“ã‚®ãƒ£ãƒƒãƒ—: {max_gap}")
        
        # Check for price jumps
        price_changes = data['close'].pct_change().abs()
        extreme_changes = price_changes[price_changes > 0.1]
        print(f"  10%ä»¥ä¸Šã®ä¾¡æ ¼å¤‰å‹•: {len(extreme_changes)}ä»¶")
        
        # Check for suspicious patterns
        zero_volumes = len(data[data['volume'] == 0])
        print(f"  ã‚¼ãƒ­ãƒœãƒªãƒ¥ãƒ¼ãƒ : {zero_volumes}ä»¶")
        
        return data
    
    def engineer_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """Engineer features (same as training)."""
        
        # Basic price features
        data['returns'] = data['close'].pct_change()
        data['log_returns'] = np.log(data['close'] / data['close'].shift(1))
        data['hl_ratio'] = (data['high'] - data['low']) / data['close']
        data['oc_ratio'] = (data['close'] - data['open']) / data['open']
        
        # Multi-timeframe returns
        for period in [1, 3, 5, 10]:
            data[f'return_{period}'] = data['close'].pct_change(period)
        
        # Simple volatility
        for window in [5, 10, 20]:
            data[f'vol_{window}'] = data['returns'].rolling(window).std()
        
        # Moving averages
        for ma in [5, 10, 20]:
            data[f'sma_{ma}'] = data['close'].rolling(ma).mean()
            data[f'price_vs_sma_{ma}'] = (data['close'] - data[f'sma_{ma}']) / data[f'sma_{ma}']
        
        # RSI (simplified)
        delta = data['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / (loss + 1e-8)
        data['rsi'] = 100 - (100 / (1 + rs))
        
        # Bollinger Bands
        bb_middle = data['close'].rolling(20).mean()
        bb_std = data['close'].rolling(20).std()
        bb_upper = bb_middle + (bb_std * 2)
        bb_lower = bb_middle - (bb_std * 2)
        data['bb_position'] = (data['close'] - bb_lower) / (bb_upper - bb_lower + 1e-8)
        
        # Volume features
        data['volume_ma'] = data['volume'].rolling(20).mean()
        data['volume_ratio'] = data['volume'] / data['volume_ma']
        
        # Momentum indicators
        data['momentum_3'] = data['close'].pct_change(3)
        data['momentum_5'] = data['close'].pct_change(5)
        
        # Simple trend
        data['trend_strength'] = (data['sma_5'] - data['sma_20']) / data['sma_20']
        
        # Time features
        data['hour'] = data.index.hour
        data['day_of_week'] = data.index.dayofweek
        
        # Fill NaN
        data = data.fillna(method='ffill').fillna(0)
        
        return data
    
    def predict_signals(self, data: pd.DataFrame) -> np.ndarray:
        """Generate trading signals using neural network."""
        
        feature_cols = [col for col in data.columns 
                       if col not in ['open', 'high', 'low', 'close', 'volume']]
        
        # Scale features
        scaled_features = self.scaler.transform(data[feature_cols])
        
        # Make predictions
        with torch.no_grad():
            X_tensor = torch.tensor(scaled_features, dtype=torch.float32).to(self.device)
            predictions = self.model(X_tensor).squeeze().cpu().numpy()
        
        return predictions
    
    def analyze_signal_distribution(self, predictions: np.ndarray, threshold: float):
        """Analyze the distribution of signals."""
        
        print(f"\nğŸ“Š ä¿¡å·åˆ†å¸ƒåˆ†æ (é–¾å€¤: {threshold}):")
        
        # Basic stats
        print(f"  äºˆæ¸¬å€¤çµ±è¨ˆ:")
        print(f"    å¹³å‡: {predictions.mean():.4f}")
        print(f"    æ¨™æº–åå·®: {predictions.std():.4f}")
        print(f"    æœ€å°: {predictions.min():.4f}")
        print(f"    æœ€å¤§: {predictions.max():.4f}")
        
        # Signal distribution
        high_conf = predictions > threshold
        print(f"\n  é«˜ä¿¡é ¼åº¦ä¿¡å·: {high_conf.sum()}ä»¶ ({high_conf.mean()*100:.2f}%)")
        
        # Histogram
        plt.figure(figsize=(10, 6))
        plt.hist(predictions, bins=50, alpha=0.7, edgecolor='black')
        plt.axvline(x=threshold, color='red', linestyle='--', label=f'Threshold: {threshold}')
        plt.xlabel('Prediction Confidence')
        plt.ylabel('Count')
        plt.title('Neural Network Prediction Distribution')
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.savefig('backtest_results/prediction_distribution.png')
        plt.close()
        
        return high_conf
    
    def simulate_simple_backtest(self, data: pd.DataFrame, predictions: np.ndarray, 
                                threshold: float, leverage: float = 1.0):
        """Simulate a simple backtest without excessive risk filters."""
        
        print(f"\nğŸ”¬ ã‚·ãƒ³ãƒ—ãƒ«ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ (ãƒ¬ãƒãƒ¬ãƒƒã‚¸: {leverage}x):")
        
        capital = 100000
        position_size = 0.02  # 2% per trade
        trades = []
        
        high_confidence_indices = np.where(predictions > threshold)[0]
        
        for i in high_confidence_indices[:100]:  # Limit to 100 trades for analysis
            if i + 10 >= len(data):
                continue
            
            entry_price = data['close'].iloc[i]
            confidence = predictions[i]
            momentum = data['momentum_3'].iloc[i]
            direction = 'long' if momentum > 0 else 'short'
            
            # Simple exit after 5 bars
            exit_price = data['close'].iloc[i + 5]
            
            # Calculate PnL
            if direction == 'long':
                raw_pnl_pct = (exit_price - entry_price) / entry_price
            else:
                raw_pnl_pct = (entry_price - exit_price) / entry_price
            
            leveraged_pnl_pct = raw_pnl_pct * leverage
            leveraged_pnl_pct -= 0.0012  # Transaction costs
            
            position_value = capital * position_size
            pnl_dollar = position_value * leveraged_pnl_pct
            
            trades.append({
                'entry_price': entry_price,
                'exit_price': exit_price,
                'direction': direction,
                'confidence': confidence,
                'raw_pnl_pct': raw_pnl_pct * 100,
                'leveraged_pnl_pct': leveraged_pnl_pct * 100,
                'pnl_dollar': pnl_dollar
            })
            
            capital += pnl_dollar
        
        if trades:
            trades_df = pd.DataFrame(trades)
            total_return = (capital - 100000) / 100000 * 100
            win_rate = len(trades_df[trades_df['pnl_dollar'] > 0]) / len(trades_df) * 100
            
            print(f"  å–å¼•æ•°: {len(trades_df)}")
            print(f"  ç·åç›Šç‡: {total_return:.2f}%")
            print(f"  å‹ç‡: {win_rate:.1f}%")
            print(f"  å¹³å‡åç›Š: {trades_df['leveraged_pnl_pct'].mean():.3f}%")
            print(f"  åç›Šæ¨™æº–åå·®: {trades_df['leveraged_pnl_pct'].std():.3f}%")
            
            # Show distribution of returns
            print(f"\n  åç›Šåˆ†å¸ƒ:")
            print(f"    -3%ä»¥ä¸‹: {len(trades_df[trades_df['leveraged_pnl_pct'] <= -3])}ä»¶")
            print(f"    -3% to -1%: {len(trades_df[(trades_df['leveraged_pnl_pct'] > -3) & (trades_df['leveraged_pnl_pct'] <= -1)])}ä»¶")
            print(f"    -1% to 0%: {len(trades_df[(trades_df['leveraged_pnl_pct'] > -1) & (trades_df['leveraged_pnl_pct'] <= 0)])}ä»¶")
            print(f"    0% to 1%: {len(trades_df[(trades_df['leveraged_pnl_pct'] > 0) & (trades_df['leveraged_pnl_pct'] <= 1)])}ä»¶")
            print(f"    1% to 3%: {len(trades_df[(trades_df['leveraged_pnl_pct'] > 1) & (trades_df['leveraged_pnl_pct'] <= 3)])}ä»¶")
            print(f"    3%ä»¥ä¸Š: {len(trades_df[trades_df['leveraged_pnl_pct'] > 3])}ä»¶")
            
            return trades_df
        
        return None
    
    def compare_with_leverage_results(self):
        """Compare results with the leverage backtest that showed high performance."""
        
        # Load saved leverage results
        try:
            leverage_trades = pd.read_csv('backtest_results/leverage_3x_trades.csv')
            print("\nğŸ“‹ ãƒ¬ãƒãƒ¬ãƒƒã‚¸3å€çµæœã®æ¤œè¨¼:")
            print(f"  ä¿å­˜ã•ã‚ŒãŸå–å¼•æ•°: {len(leverage_trades)}")
            print(f"  å‹ç‡: {len(leverage_trades[leverage_trades['pnl_dollar'] > 0]) / len(leverage_trades) * 100:.1f}%")
            print(f"  å¹³å‡PnL: ${leverage_trades['pnl_dollar'].mean():.2f}")
            
            # Check for selection bias
            print(f"\nğŸ” é¸æŠãƒã‚¤ã‚¢ã‚¹ãƒã‚§ãƒƒã‚¯:")
            print(f"  å¹³å‡ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚º: {leverage_trades['position_size'].mean():.4f}")
            print(f"  ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºæ¨™æº–åå·®: {leverage_trades['position_size'].std():.4f}")
            
            # Check drawdown at entry
            print(f"\n  ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ™‚ã®ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³:")
            print(f"    å¹³å‡: {leverage_trades['drawdown_at_entry'].mean():.3f}%")
            print(f"    æœ€å°: {leverage_trades['drawdown_at_entry'].min():.3f}%")
            print(f"    æœ€å¤§: {leverage_trades['drawdown_at_entry'].max():.3f}%")
            
        except:
            print("\nâŒ ãƒ¬ãƒãƒ¬ãƒƒã‚¸å–å¼•çµæœãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")


def main():
    """Verify leverage backtest results."""
    
    print("="*80)
    print("ğŸ” ãƒ¬ãƒãƒ¬ãƒƒã‚¸ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®æ¤œè¨¼")
    print("="*80)
    
    verifier = VerifyLeverageResults()
    
    # Load model and data
    verifier.load_model()
    data = verifier.load_test_data()
    
    # Engineer features
    data = verifier.engineer_features(data)
    
    # Generate predictions
    predictions = verifier.predict_signals(data)
    
    # Analyze signal distribution
    threshold = 0.65
    high_conf = verifier.analyze_signal_distribution(predictions, threshold)
    
    # Run simple backtest without excessive filters
    print("\n" + "="*60)
    print("æ¯”è¼ƒ: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãªã—ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ")
    print("="*60)
    
    # Test with no leverage
    trades_1x = verifier.simulate_simple_backtest(data, predictions, threshold, leverage=1.0)
    
    # Test with 3x leverage
    trades_3x = verifier.simulate_simple_backtest(data, predictions, threshold, leverage=3.0)
    
    # Compare with saved results
    verifier.compare_with_leverage_results()
    
    print("\n" + "="*80)
    print("ğŸ¯ çµè«–:")
    print("="*80)
    
    print("\nå•é¡Œç‚¹ã®è¦ç´„:")
    print("1. âœ… ãƒ‡ãƒ¼ã‚¿ã¯æœ¬ç‰©ï¼ˆãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§ã¯ãªã„ï¼‰")
    print("2. âš ï¸ éåº¦ã«å³ã—ã„ãƒªã‚¹ã‚¯ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«ã‚ˆã‚‹é¸æŠãƒã‚¤ã‚¢ã‚¹")
    print("3. âš ï¸ 1,554ä¿¡å·ã‹ã‚‰31å–å¼•ã®ã¿ï¼ˆ98%ãŒãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼‰")
    print("4. âš ï¸ æ—©ã™ãã‚‹åˆ©ç¢ºï¼ˆ1.5%ï¼‰ã¨æåˆ‡ã‚Šï¼ˆ3%ï¼‰")
    print("\nã“ã‚Œã‚‰ã®æ¡ä»¶ã«ã‚ˆã‚Šã€æœ€ã‚‚æœ‰åˆ©ãªå–å¼•ã®ã¿ãŒé¸æŠã•ã‚Œã€")
    print("ç•°å¸¸ã«é«˜ã„å‹ç‡ã¨Sharpeæ¯”ãŒå®Ÿç¾ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    print("\nå®Ÿéš›ã®å–å¼•ã§ã¯ã€ã“ã®ã‚ˆã†ãªé¸æŠçš„ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã¯")
    print("å®Ÿè¡Œå¯èƒ½ãªå–å¼•æ©Ÿä¼šã‚’å¤§å¹…ã«åˆ¶é™ã—ã¦ã—ã¾ã„ã¾ã™ã€‚")


if __name__ == "__main__":
    main()