#!/usr/bin/env python3
"""
é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«26æ¬¡å…ƒå¾©å…ƒ - ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆ
- ã‚ˆã‚Šä½ã„åˆ©ç›Šé–¾å€¤ã§ååˆ†ãªæ­£ä¾‹ã‚’ç¢ºä¿
- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿å¯¾å¿œ
- å®Ÿéš›ã®å–å¼•ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆã«æœ€é©åŒ–
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import duckdb
from typing import Dict, List, Tuple
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import roc_auc_score, classification_report
from sklearn.utils.class_weight import compute_class_weight
import warnings
warnings.filterwarnings('ignore')

# ãƒ­ã‚°è¨­å®š
import logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ONNXå¤‰æ›ç”¨
try:
    import onnx
    import skl2onnx
    from skl2onnx import convert_sklearn
    from skl2onnx.common.data_types import FloatTensorType
    ONNX_AVAILABLE = True
except ImportError:
    print("âš ï¸ ONNXå¤‰æ›ã‚¹ã‚­ãƒƒãƒ—ï¼ˆä¾å­˜é–¢ä¿‚ä¸è¶³ï¼‰")
    ONNX_AVAILABLE = False

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class BalancedHighPerformanceModel26D:
    """ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆ26æ¬¡å…ƒé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(self, profit_threshold: float = 0.002):  # ã‚ˆã‚Šä½ã„é–¾å€¤
        self.profit_threshold = profit_threshold
        self.scaler = StandardScaler()
        self.model = None
        
        # æœ€é‡è¦26ç‰¹å¾´é‡
        self.top_26_features = [
            'returns', 'log_returns', 'hl_ratio', 'oc_ratio',
            'return_1', 'return_3', 'return_5', 'return_10', 'return_15', 'return_30',
            'vol_5', 'vol_10', 'vol_20',
            'price_vs_sma_5', 'price_vs_sma_10', 'price_vs_sma_20',
            'rsi', 'bb_position', 'macd_hist',
            'volume_ratio', 'log_volume', 'volume_price_change',
            'momentum_3', 'momentum_5',
            'trend_strength', 'price_above_ma'
        ]
        
        logger.info(f"ãƒãƒ©ãƒ³ã‚¹èª¿æ•´26æ¬¡å…ƒãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–: {len(self.top_26_features)}ç‰¹å¾´é‡")
        
    def load_data(self, symbol: str = "BTCUSDT", limit: int = 15000) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        print(f"ğŸ“Š {symbol}ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ï¼ˆ{limit:,}ä»¶ï¼‰...")
        
        try:
            conn = duckdb.connect("data/historical_data.duckdb", read_only=True)
            
            query = f"""
            SELECT 
                timestamp,
                open,
                high,
                low,
                close,
                volume
            FROM klines_{symbol.lower()}
            WHERE timestamp >= '2024-05-01'
            ORDER BY timestamp DESC
            LIMIT {limit}
            """
            
            data = conn.execute(query).df()
            
            if len(data) == 0:
                print("âŒ å®Ÿãƒ‡ãƒ¼ã‚¿ãªã—ã€‚ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨...")
                conn.close()
                return self._generate_balanced_data(limit)
            
            data['timestamp'] = pd.to_datetime(data['timestamp'])
            data.set_index('timestamp', inplace=True)
            data = data.sort_index()
            
            conn.close()
            print(f"âœ… {len(data):,}ä»¶èª­ã¿è¾¼ã¿å®Œäº†")
            
            return data
            
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_balanced_data(limit)
    
    def _generate_balanced_data(self, limit: int) -> pd.DataFrame:
        """ãƒãƒ©ãƒ³ã‚¹å–ã‚ŒãŸã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿"""
        print(f"ğŸ“Š ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­ï¼ˆ{limit:,}ä»¶ï¼‰...")
        
        dates = pd.date_range('2024-05-01', periods=limit, freq='5min')
        
        # ã‚ˆã‚Šå¤‰å‹•ã®å¤§ãã„ãƒªã‚¢ãƒ«ãªãƒ‡ãƒ¼ã‚¿
        np.random.seed(42)
        base_price = 65000
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰æœŸé–“ã¨ãƒ¬ãƒ³ã‚¸æœŸé–“ã‚’æ··åœ¨
        trend_periods = np.random.choice([0, 1], size=len(dates), p=[0.7, 0.3])  # 30%ãŒãƒˆãƒ¬ãƒ³ãƒ‰
        
        returns = []
        volatility = 0.003  # ã‚„ã‚„é«˜ã‚ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        
        for i, is_trend in enumerate(trend_periods):
            if is_trend:
                # ãƒˆãƒ¬ãƒ³ãƒ‰æœŸé–“ï¼šæ–¹å‘æ€§ã®ã‚ã‚‹ãƒªã‚¿ãƒ¼ãƒ³
                trend_direction = np.random.choice([-1, 1])
                base_return = trend_direction * 0.0005  # 0.05%ã®ãƒˆãƒ¬ãƒ³ãƒ‰
                noise = np.random.normal(0, volatility * 0.8)
                return_val = base_return + noise
            else:
                # ãƒ¬ãƒ³ã‚¸æœŸé–“ï¼šå¹³å‡å›å¸°
                if i > 20:
                    # éå»20æœŸé–“ã®å¹³å‡ã‹ã‚‰ã®ä¹–é›¢ã‚’ä¿®æ­£
                    recent_returns = returns[-20:]
                    cum_return = sum(recent_returns)
                    mean_reversion = -0.3 * cum_return  # å¹³å‡å›å¸°åŠ›
                    return_val = mean_reversion + np.random.normal(0, volatility)
                else:
                    return_val = np.random.normal(0, volatility)
            
            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            if i > 0 and abs(returns[-1]) > volatility * 2:
                return_val *= 1.5  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ãŒç¶šã
            
            returns.append(return_val)
        
        # ä¾¡æ ¼ç³»åˆ—
        log_prices = np.log(base_price) + np.cumsum(returns)
        prices = np.exp(log_prices)
        
        # OHLC
        intraday_vol = np.random.uniform(0.0005, 0.002, len(dates))
        high_prices = prices * (1 + intraday_vol)
        low_prices = prices * (1 - intraday_vol)
        
        data = pd.DataFrame({
            'timestamp': dates,
            'open': prices,
            'high': high_prices,
            'low': low_prices,
            'close': prices,
            'volume': np.random.lognormal(9.5, 1.2, len(dates))
        })
        
        data.set_index('timestamp', inplace=True)
        print(f"âœ… ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(data):,}ä»¶")
        
        return data

    def create_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """26æ¬¡å…ƒç‰¹å¾´é‡ç”Ÿæˆ"""
        print("ğŸ”§ 26æ¬¡å…ƒç‰¹å¾´é‡ç”Ÿæˆä¸­...")
        
        df = data.copy()
        
        # åŸºæœ¬ä¾¡æ ¼ç‰¹å¾´é‡
        df['returns'] = df['close'].pct_change()
        df['log_returns'] = np.log(df['close'] / df['close'].shift(1))
        df['hl_ratio'] = (df['high'] - df['low']) / df['close']
        df['oc_ratio'] = (df['close'] - df['open']) / df['open']
        
        # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ 
        for period in [1, 3, 5, 10, 15, 30]:
            df[f'return_{period}'] = df['close'].pct_change(period)
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        for window in [5, 10, 20]:
            df[f'vol_{window}'] = df['returns'].rolling(window).std()
        
        # ç§»å‹•å¹³å‡
        for ma in [5, 10, 20]:
            df[f'sma_{ma}'] = df['close'].rolling(ma).mean()
            df[f'price_vs_sma_{ma}'] = (df['close'] - df[f'sma_{ma}']) / df[f'sma_{ma}']
        
        # RSI
        delta = df['close'].diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
        rs = gain / (loss + 1e-8)
        df['rsi'] = 100 - (100 / (1 + rs))
        
        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
        bb_middle = df['close'].rolling(20).mean()
        bb_std = df['close'].rolling(20).std()
        bb_upper = bb_middle + (bb_std * 2)
        bb_lower = bb_middle - (bb_std * 2)
        df['bb_position'] = (df['close'] - bb_lower) / (bb_upper - bb_lower + 1e-8)
        
        # MACD
        ema_12 = df['close'].ewm(span=12).mean()
        ema_26 = df['close'].ewm(span=26).mean()
        df['macd'] = ema_12 - ema_26
        df['macd_signal'] = df['macd'].ewm(span=9).mean()
        df['macd_hist'] = df['macd'] - df['macd_signal']
        
        # ãƒœãƒªãƒ¥ãƒ¼ãƒ 
        df['volume_ma'] = df['volume'].rolling(20).mean()
        df['volume_ratio'] = df['volume'] / df['volume_ma']
        df['log_volume'] = np.log(df['volume'] + 1)
        df['volume_price_change'] = df['volume_ratio'] * abs(df['returns'])
        
        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
        df['momentum_3'] = df['close'].pct_change(3)
        df['momentum_5'] = df['close'].pct_change(5)
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰
        df['trend_strength'] = (df['sma_5'] - df['sma_20']) / df['sma_20']
        df['price_above_ma'] = (df['close'] > df['sma_20']).astype(int)
        
        print(f"âœ… 26ç‰¹å¾´é‡ç”Ÿæˆå®Œäº†")
        return df
    
    def create_balanced_labels(self, data: pd.DataFrame) -> pd.Series:
        """ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ©ãƒ™ãƒ«ç”Ÿæˆ"""
        print("ğŸ¯ ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ©ãƒ™ãƒ«ç”Ÿæˆä¸­...")
        
        transaction_cost = 0.0008  # ã‚„ã‚„ä½ã‚ã®æ‰‹æ•°æ–™
        horizons = [3, 5, 8, 12]  # ã‚ˆã‚ŠçŸ­æœŸã®æ™‚é–“è»¸
        
        all_labels = []
        
        for horizon in horizons:
            future_return = data['close'].pct_change(horizon).shift(-horizon)
            
            # ãƒ­ãƒ³ã‚°ãƒ»ã‚·ãƒ§ãƒ¼ãƒˆæ©Ÿä¼š
            long_profit = future_return - transaction_cost
            short_profit = -future_return - transaction_cost
            
            # ã‚ˆã‚Šä½ã„é–¾å€¤ã§æ©Ÿä¼šã‚’å¢—ã‚„ã™
            profitable = ((long_profit > self.profit_threshold) | 
                         (short_profit > self.profit_threshold)).astype(int)
            
            all_labels.append(profitable)
        
        # è¤‡æ•°æ™‚é–“è»¸ã§ã®åˆæ„
        combined_labels = pd.concat(all_labels, axis=1).any(axis=1).astype(int)
        
        positive_rate = combined_labels.mean()
        print(f"âœ… ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ©ãƒ™ãƒ«å®Œäº†")
        print(f"   é™½æ€§ç‡: {positive_rate:.1%} (ç›®æ¨™: 5-20%)")
        print(f"   æ™‚é–“è»¸åˆ¥: {[f'{h}: {l.mean():.1%}' for h, l in zip(horizons, all_labels)]}")
        
        if positive_rate < 0.02:  # 2%æœªæº€ãªã‚‰è­¦å‘Š
            print("âš ï¸ é™½æ€§ç‡ãŒä½ã™ãã¾ã™ã€‚é–¾å€¤èª¿æ•´ã‚’æ¨å¥¨")
        elif positive_rate > 0.4:  # 40%è¶…ãªã‚‰è­¦å‘Š
            print("âš ï¸ é™½æ€§ç‡ãŒé«˜ã™ãã¾ã™ã€‚é–¾å€¤èª¿æ•´ã‚’æ¨å¥¨")
        
        return combined_labels

    def prepare_data(self, data: pd.DataFrame) -> Tuple[pd.DataFrame, pd.Series]:
        """ãƒ‡ãƒ¼ã‚¿æº–å‚™"""
        print("ğŸ—‚ï¸ ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ‡ãƒ¼ã‚¿æº–å‚™ä¸­...")
        
        y = self.create_balanced_labels(data)
        X = data[self.top_26_features].copy()
        
        # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿
        valid_mask = ~(X.isnull().any(axis=1) | y.isnull())
        X = X[valid_mask]
        y = y[valid_mask]
        
        # æ¬ æå€¤å‡¦ç†
        for col in X.columns:
            X[col] = X[col].fillna(X[col].median())
        
        # æœ€ä½ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
        positive_samples = y.sum()
        negative_samples = len(y) - positive_samples
        
        print(f"âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†:")
        print(f"   ç·ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X):,}")
        print(f"   æ­£ä¾‹: {positive_samples:,} ({y.mean():.1%})")
        print(f"   è² ä¾‹: {negative_samples:,}")
        print(f"   26ç‰¹å¾´é‡ç¢ºèª: {len(X.columns)}")
        
        # æœ€ä½é™ã®æ­£ä¾‹ãŒå¿…è¦
        if positive_samples < 50:
            print("âŒ æ­£ä¾‹ã‚µãƒ³ãƒ—ãƒ«ä¸è¶³ã€‚é–¾å€¤ã‚’ä¸‹ã’ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™")
            return X, y
        
        return X, y

    def train_balanced_model(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""
        print("ğŸ¤– ãƒãƒ©ãƒ³ã‚¹èª¿æ•´Random Forestè¨“ç·´ä¸­...")
        
        # ã‚¯ãƒ©ã‚¹é‡ã¿è¨ˆç®—
        classes = np.unique(y)
        if len(classes) < 2:
            print("âŒ ã‚¯ãƒ©ã‚¹ãŒ1ã¤ã—ã‹ã‚ã‚Šã¾ã›ã‚“")
            return {'auc_mean': 0.0, 'auc_std': 0.0}
        
        class_weights = compute_class_weight('balanced', classes=classes, y=y)
        class_weight_dict = dict(zip(classes, class_weights))
        
        print(f"   ã‚¯ãƒ©ã‚¹é‡ã¿: {class_weight_dict}")
        
        # é«˜æ€§èƒ½Random Forestï¼ˆãƒãƒ©ãƒ³ã‚¹èª¿æ•´ç‰ˆï¼‰
        self.model = RandomForestClassifier(
            n_estimators=250,        # ã‚„ã‚„å¤šã‚ã®ãƒ„ãƒªãƒ¼
            max_depth=12,           # é©åº¦ãªæ·±ã•
            min_samples_split=8,    # åˆ†å‰²ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«
            min_samples_leaf=4,     # è‘‰ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«
            class_weight='balanced', # è‡ªå‹•ãƒãƒ©ãƒ³ã‚¹èª¿æ•´
            random_state=42,
            n_jobs=-1,
            max_features='sqrt',     # ç‰¹å¾´é‡ã‚µãƒ–ã‚»ãƒƒãƒˆ
            bootstrap=True,
            oob_score=True          # Out-of-bagè©•ä¾¡
        )
        
        # å±¤åŒ–Kåˆ†å‰²äº¤å·®æ¤œè¨¼ï¼ˆæ™‚ç³»åˆ—ã§ãªã„ã®ã§Stratifiedä½¿ç”¨ï¼‰
        from sklearn.model_selection import StratifiedKFold
        skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        
        auc_scores = []
        
        for train_idx, val_idx in skf.split(X, y):
            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
            
            # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
            temp_model = RandomForestClassifier(**self.model.get_params())
            temp_model.fit(X_train, y_train)
            
            # äºˆæ¸¬
            y_pred_proba = temp_model.predict_proba(X_val)[:, 1]
            auc = roc_auc_score(y_val, y_pred_proba)
            auc_scores.append(auc)
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.model.fit(X, y)
        
        # ç‰¹å¾´é‡é‡è¦åº¦
        feature_importance = dict(zip(X.columns, self.model.feature_importances_))
        sorted_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)
        
        # Out-of-bagè©•ä¾¡
        oob_score = getattr(self.model, 'oob_score_', None)
        
        print(f"âœ… ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")
        print(f"   äº¤å·®æ¤œè¨¼AUC: {np.mean(auc_scores):.3f}Â±{np.std(auc_scores):.3f}")
        if oob_score:
            print(f"   OOBç²¾åº¦: {oob_score:.3f}")
        print(f"   é‡è¦ç‰¹å¾´é‡TOP5: {[f[0] for f in sorted_features[:5]]}")
        
        return {
            'auc_mean': np.mean(auc_scores),
            'auc_std': np.std(auc_scores),
            'auc_scores': auc_scores,
            'oob_score': oob_score,
            'feature_importance': feature_importance
        }

    def evaluate_thresholds(self, X: pd.DataFrame, y: pd.Series) -> Dict:
        """é–¾å€¤åˆ¥è©•ä¾¡"""
        print("ğŸ“ˆ é–¾å€¤åˆ¥å–å¼•ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³...")
        
        if not self.model:
            return {}
        
        y_proba = self.model.predict_proba(X)[:, 1]
        
        results = {}
        
        for threshold in np.arange(0.3, 0.9, 0.05):
            threshold = round(threshold, 2)
            signals = (y_proba > threshold)
            
            if signals.sum() > 0:
                accuracy = y[signals].mean()
                signal_count = signals.sum()
                
                # æœŸå¾…åç›Šè¨ˆç®—
                expected_return = (accuracy - 0.5) * 0.015  # 1.5%ã®æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³
                net_return = expected_return - 0.0008  # æ‰‹æ•°æ–™å·®ã—å¼•ã
                
                results[threshold] = {
                    'signal_count': int(signal_count),
                    'accuracy': float(accuracy),
                    'expected_return_per_trade': float(net_return),
                    'total_signals_rate': float(signal_count / len(X))
                }
            else:
                results[threshold] = {
                    'signal_count': 0,
                    'accuracy': 0,
                    'expected_return_per_trade': 0,
                    'total_signals_rate': 0
                }
        
        return results

    def convert_to_onnx(self, model_dir: Path) -> bool:
        """ONNXå¤‰æ›"""
        if not ONNX_AVAILABLE or not self.model:
            print("âŒ ONNXå¤‰æ›ã‚¹ã‚­ãƒƒãƒ—")
            return False
        
        print("ğŸ”„ ONNXã«å¤‰æ›ä¸­...")
        
        try:
            initial_type = [('float_input', FloatTensorType([None, 26]))]
            onnx_model = convert_sklearn(
                self.model,
                initial_types=initial_type,
                target_opset=14
            )
            
            onnx_path = model_dir / "model.onnx"
            with open(onnx_path, "wb") as f:
                f.write(onnx_model.SerializeToString())
            
            print(f"âœ… ONNXå¤‰æ›å®Œäº†: {onnx_path}")
            return True
            
        except Exception as e:
            print(f"âŒ ONNXå¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def save_model(self, results: Dict, model_dir: str = "models/balanced_restored_26d"):
        """ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""
        model_path = Path(model_dir)
        model_path.mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­: {model_path}")
        
        # ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä¿å­˜
        joblib.dump(self.model, model_path / "model.pkl")
        joblib.dump(self.scaler, model_path / "scaler.pkl")
        
        # ONNXå¤‰æ›
        onnx_success = self.convert_to_onnx(model_path)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        import json
        from datetime import datetime
        
        metadata = {
            "model_type": "balanced_restored_high_performance_26d",
            "feature_count": 26,
            "feature_names": self.top_26_features,
            "training_date": datetime.now().strftime("%Y%m%d_%H%M%S"),
            "model_version": "4.1_balanced_restored",
            "performance": results,
            "onnx_converted": onnx_success,
            "config": {
                "profit_threshold": self.profit_threshold,
                "transaction_cost": 0.0008,
                "horizons": [3, 5, 8, 12],
                "target_auc": 0.867,
                "balanced_approach": True
            }
        }
        
        with open(model_path / "metadata.json", 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… ä¿å­˜å®Œäº†: {model_path}")
        return metadata

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("="*70)
    print("ğŸš€ ãƒãƒ©ãƒ³ã‚¹èª¿æ•´26æ¬¡å…ƒé«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«å¾©å…ƒ")
    print("="*70)
    
    # åˆæœŸåŒ–ï¼ˆã‚ˆã‚Šä½ã„é–¾å€¤ï¼‰
    model = BalancedHighPerformanceModel26D(profit_threshold=0.002)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data = model.load_data(limit=15000)
    
    if len(data) < 2000:
        print("âŒ ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
        return None, None
    
    # ç‰¹å¾´é‡ç”Ÿæˆ
    data_with_features = model.create_features(data)
    
    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    X, y = model.prepare_data(data_with_features)
    
    if len(X) < 1000 or y.sum() < 50:
        print("âŒ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¾ãŸã¯æ­£ä¾‹ãŒä¸è¶³")
        return None, None
    
    # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
    results = model.train_balanced_model(X, y)
    
    # é–¾å€¤è©•ä¾¡
    threshold_results = model.evaluate_thresholds(X, y)
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    metadata = model.save_model(results)
    
    # çµæœè¡¨ç¤º
    print("\n" + "="*70)
    print("ğŸ“Š ãƒãƒ©ãƒ³ã‚¹èª¿æ•´26æ¬¡å…ƒãƒ¢ãƒ‡ãƒ«å¾©å…ƒçµæœ")
    print("="*70)
    
    auc = results['auc_mean']
    print(f"\nğŸ¯ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:")
    print(f"   Random Forest AUC: {auc:.3f}Â±{results['auc_std']:.3f}")
    if results.get('oob_score'):
        print(f"   OOBç²¾åº¦: {results['oob_score']:.3f}")
    
    # æ€§èƒ½è©•ä¾¡
    if auc >= 0.75:
        print(f"\nğŸ‰ å„ªç§€ãªæ€§èƒ½ï¼ç›®æ¨™AUC 0.867ã«è¿‘ã„")
        status = "âœ… ãƒ‡ãƒ—ãƒ­ã‚¤æ¨å¥¨"
    elif auc >= 0.65:
        print(f"\nâœ… è‰¯å¥½ãªæ€§èƒ½ï¼å®Ÿç”¨ãƒ¬ãƒ™ãƒ«")
        status = "âœ… ãƒ‡ãƒ—ãƒ­ã‚¤å¯èƒ½"
    elif auc >= 0.55:
        print(f"\nğŸŸ¨ æ”¹å–„è¦‹è¾¼ã¿ã€‚ç¾è¡Œã‚·ã‚¹ãƒ†ãƒ ã‚ˆã‚Šè‰¯ã„å¯èƒ½æ€§")
        status = "ğŸŸ¨ æ¡ä»¶ä»˜ããƒ‡ãƒ—ãƒ­ã‚¤"
    else:
        print(f"\nâŒ æ€§èƒ½ä¸è¶³")
        status = "âŒ è¦æ”¹å–„"
    
    print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ:")
    print(f"   ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(X):,}")
    print(f"   æ­£ä¾‹ç‡: {y.mean():.1%}")
    print(f"   ç‰¹å¾´é‡: 26æ¬¡å…ƒ")
    
    # æœ€é©é–¾å€¤
    print(f"\nğŸ“ˆ æœ€é©å–å¼•é–¾å€¤ï¼ˆä¸Šä½3ã¤ï¼‰:")
    sorted_thresholds = sorted(threshold_results.items(), 
                              key=lambda x: x[1]['expected_return_per_trade'], reverse=True)
    
    for i, (threshold, result) in enumerate(sorted_thresholds[:3]):
        if result['signal_count'] > 0:
            print(f"   {i+1}. é–¾å€¤{threshold}: {result['signal_count']}ã‚·ã‚°ãƒŠãƒ« "
                  f"({result['total_signals_rate']:.1%}), "
                  f"ç²¾åº¦{result['accuracy']:.1%}, "
                  f"æœŸå¾…åç›Š{result['expected_return_per_trade']:.3%}")
    
    print(f"\nğŸ¯ ãƒ‡ãƒ—ãƒ­ã‚¤çŠ¶æ³: {status}")
    print(f"ğŸ’¾ ä¿å­˜å ´æ‰€: models/balanced_restored_26d/")
    
    if metadata.get('onnx_converted'):
        print(f"ğŸ”„ ONNXå¤‰æ›: âœ… å®Œäº†ï¼ˆç¾è¡Œã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œï¼‰")
    
    print("\nğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("1. dynamic_trading_coordinator.pyã§ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹å¤‰æ›´")
    print("2. å®Ÿã‚·ã‚¹ãƒ†ãƒ ã§ã®å‹•ä½œç¢ºèª")
    print("3. é–¾å€¤70-80%ã§ã®ãƒ©ã‚¤ãƒ–ãƒ†ã‚¹ãƒˆ")
    
    return model, results

if __name__ == "__main__":
    try:
        model, results = main()
        if model and results:
            auc = results['auc_mean']
            print(f"\nâœ… ãƒãƒ©ãƒ³ã‚¹èª¿æ•´å¾©å…ƒå®Œäº†! AUC: {auc:.3f}")
            if auc >= 0.65:
                print("ğŸ¯ ãƒ‡ãƒ—ãƒ­ã‚¤æº–å‚™å®Œäº†")
            else:
                print("ğŸ”§ ã•ã‚‰ãªã‚‹èª¿æ•´ãŒæ¨å¥¨ã•ã‚Œã¾ã™")
        else:
            print("\nâŒ å¾©å…ƒå¤±æ•—")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()