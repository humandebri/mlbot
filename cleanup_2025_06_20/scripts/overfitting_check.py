#!/usr/bin/env python3
"""
Overfitting check using completely unseen data (Aug-Oct 2024).
This validates if our model generalizes to future periods.
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
import duckdb
import joblib
import warnings
warnings.filterwarnings('ignore')

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.common.logging import get_logger, setup_logging

setup_logging()
logger = get_logger(__name__)


def overfitting_check():
    """Check for overfitting using completely unseen data."""
    
    logger.info("Running overfitting check with unseen data (Aug-Oct 2024)")
    
    # Load model
    try:
        model = joblib.load("models/simple_ensemble/random_forest_model.pkl")
        logger.info("Loaded Random Forest model")
    except:
        logger.error("Could not load model")
        return

    # Load UNSEEN data (Aug-Oct 2024) - model was trained on Jan-Apr, tested on May-Jul
    conn = duckdb.connect("data/historical_data.duckdb")
    query = """
    SELECT 
        timestamp,
        open,
        high,
        low,
        close,
        volume
    FROM klines_btcusdt
    WHERE timestamp >= '2024-08-01'
      AND timestamp <= '2024-10-31'  -- Completely unseen 3 months
    ORDER BY timestamp
    """
    
    data = conn.execute(query).df()
    data['timestamp'] = pd.to_datetime(data['timestamp'])
    data.set_index('timestamp', inplace=True)
    conn.close()
    
    logger.info(f"Loaded {len(data)} UNSEEN test records (Aug-Oct 2024)")
    
    if len(data) == 0:
        logger.warning("No data available for this period")
        return None
    
    # Create same features as training (EXACTLY the same pipeline)
    data['returns'] = data['close'].pct_change()
    data['log_returns'] = np.log(data['close'] / data['close'].shift(1))
    data['hl_ratio'] = (data['high'] - data['low']) / data['close']
    data['oc_ratio'] = (data['close'] - data['open']) / data['open']
    
    for period in [1, 3, 5, 10, 15, 30]:
        data[f'return_{period}'] = data['close'].pct_change(period)
    
    for window in [5, 10, 20, 30]:
        data[f'vol_{window}'] = data['returns'].rolling(window).std()
    
    for ma in [5, 10, 20]:
        data[f'sma_{ma}'] = data['close'].rolling(ma).mean()
        data[f'price_vs_sma_{ma}'] = (data['close'] - data[f'sma_{ma}']) / data[f'sma_{ma}']
    
    data['momentum_3'] = data['close'].pct_change(3)
    data['momentum_5'] = data['close'].pct_change(5)
    data['momentum_10'] = data['close'].pct_change(10)
    
    data['volume_ma'] = data['volume'].rolling(20).mean()
    data['volume_ratio'] = data['volume'] / data['volume_ma']
    data['log_volume'] = np.log(data['volume'] + 1)
    
    # RSI
    delta = data['close'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / (loss + 1e-8)
    data['rsi'] = 100 - (100 / (1 + rs))
    
    # Bollinger Bands
    bb_middle = data['close'].rolling(20).mean()
    bb_std = data['close'].rolling(20).std()
    bb_upper = bb_middle + (bb_std * 2)
    bb_lower = bb_middle - (bb_std * 2)
    data['bb_position'] = (data['close'] - bb_lower) / (bb_upper - bb_lower + 1e-8)
    
    data['trend_strength'] = (data['sma_5'] - data['sma_20']) / data['sma_20']
    data['price_above_ma'] = (data['close'] > data['sma_20']).astype(int)
    data['volume_price_change'] = data['volume_ratio'] * abs(data['returns'])
    data['high_vol'] = (data['vol_20'] > data['vol_20'].rolling(50).quantile(0.8)).astype(int)
    data['low_vol'] = (data['vol_20'] < data['vol_20'].rolling(50).quantile(0.2)).astype(int)
    data['hour'] = data.index.hour
    data['day_of_week'] = data.index.dayofweek
    
    # Fill NaN exactly as in training
    feature_cols = [col for col in data.columns if col not in ['open', 'high', 'low', 'close', 'volume']]
    for col in feature_cols:
        data[col] = data[col].fillna(data[col].median())
    
    data = data.dropna()
    
    # Get predictions
    X = data[feature_cols]
    predictions = model.predict_proba(X)[:, 1]
    
    print("\n" + "="*80)
    print("ğŸ” éå­¦ç¿’ãƒã‚§ãƒƒã‚¯ - å®Œå…¨æœªä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ (2024å¹´8-10æœˆ)")
    print("="*80)
    
    print(f"\nğŸ“Š ãƒ‡ãƒ¼ã‚¿æœŸé–“: 2024å¹´8æœˆ1æ—¥ - 10æœˆ31æ—¥ (3ãƒ¶æœˆ)")
    print(f"  ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {len(data):,}")
    print(f"  ä½¿ç”¨çŠ¶æ³: âŒ å®Œå…¨æœªä½¿ç”¨ (training: Jan-Apr, validation: May-Jul)")
    
    # Test multiple confidence thresholds on unseen data
    confidence_thresholds = [0.85, 0.90, 0.95]
    unseen_results = {}
    
    for threshold in confidence_thresholds:
        logger.info(f"Testing confidence threshold: {threshold} on UNSEEN data")
        
        capital = 100000
        position_size = 0.01  # Conservative 1%
        fee_rate = 0.0008  # Lower fee assumption
        trades = []
        
        high_confidence_indices = np.where(predictions > threshold)[0]
        logger.info(f"Found {len(high_confidence_indices)} signals at {threshold} threshold")
        
        # Test up to 100 trades
        for i in high_confidence_indices[:100]:
            if i + 5 >= len(data):
                continue
                
            entry_price = data['close'].iloc[i]
            confidence = predictions[i]
            
            # Conservative direction selection
            direction = 'long' if data['return_3'].iloc[i] > 0 else 'short'
            
            exit_price = data['close'].iloc[i + 5]
            
            # Calculate PnL
            if direction == 'long':
                pnl_pct = (exit_price - entry_price) / entry_price
            else:
                pnl_pct = (entry_price - exit_price) / entry_price
            
            # Subtract fees
            pnl_pct -= fee_rate
            
            # Calculate dollar PnL
            position_value = capital * position_size
            pnl_dollar = position_value * pnl_pct
            
            trades.append({
                'timestamp': data.index[i],
                'pnl_dollar': pnl_dollar,
                'confidence': confidence,
                'direction': direction
            })
            
            capital += pnl_dollar
        
        if trades:
            trades_df = pd.DataFrame(trades)
            total_return = (capital - 100000) / 100000 * 100
            win_rate = len(trades_df[trades_df['pnl_dollar'] > 0]) / len(trades_df) * 100
            avg_trade = trades_df['pnl_dollar'].mean()
            monthly_return = total_return / 3
            
            unseen_results[threshold] = {
                'trades': len(trades_df),
                'total_return': total_return,
                'monthly_return': monthly_return,
                'win_rate': win_rate,
                'avg_trade': avg_trade
            }
    
    # Display results
    print(f"\nğŸ¯ æœªä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
    print(f"{'ä¿¡é ¼åº¦':<8} {'å–å¼•æ•°':<8} {'æœˆæ¬¡åç›Šç‡':<12} {'å‹ç‡':<8} {'å¹³å‡å–å¼•':<12}")
    print("-" * 60)
    
    best_unseen_return = -float('inf')
    best_unseen_threshold = None
    
    for threshold, result in unseen_results.items():
        print(f"{threshold:<8} {result['trades']:<8} {result['monthly_return']:>10.2f}% "
              f"{result['win_rate']:>6.1f}% ${result['avg_trade']:>9.2f}")
        
        if result['monthly_return'] > best_unseen_return:
            best_unseen_return = result['monthly_return']
            best_unseen_threshold = threshold
    
    # Overfitting analysis
    print(f"\nğŸ” éå­¦ç¿’åˆ†æ:")
    
    # Compare with previous test results (May-Jul)
    previous_best = -0.01  # From previous test
    
    print(f"  å‰å›ãƒ†ã‚¹ãƒˆ (May-Jul): {previous_best:.2f}% æœˆæ¬¡")
    print(f"  ä»Šå›ãƒ†ã‚¹ãƒˆ (Aug-Oct): {best_unseen_return:.2f}% æœˆæ¬¡")
    
    performance_difference = abs(best_unseen_return - previous_best)
    
    if performance_difference < 0.1:
        overfitting_status = "âœ… éå­¦ç¿’ãªã— - ãƒ¢ãƒ‡ãƒ«ã¯æ±åŒ–æ€§è‰¯å¥½"
    elif performance_difference < 0.2:
        overfitting_status = "âš ï¸ è»½å¾®ãªéå­¦ç¿’ã®å¯èƒ½æ€§"
    else:
        overfitting_status = "âŒ éå­¦ç¿’ã®å¯èƒ½æ€§å¤§ - ãƒ¢ãƒ‡ãƒ«è¦‹ç›´ã—å¿…è¦"
    
    print(f"  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å·®: {performance_difference:.2f}%")
    print(f"  ğŸ“Š è©•ä¾¡: {overfitting_status}")
    
    # Final assessment
    print(f"\nğŸ¯ æœ€çµ‚è©•ä¾¡:")
    if best_unseen_return > 0:
        print(f"  ğŸ‰ æœªä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã§åç›Šæ€§é”æˆï¼")
        print(f"  æœˆæ¬¡åç›Šç‡: {best_unseen_return:.2f}%")
        print(f"  å¹´æ¬¡è¦‹è¾¼ã¿: {best_unseen_return * 12:.1f}%")
        print(f"  æœ€é©ä¿¡é ¼åº¦: {best_unseen_threshold}")
        print(f"  âœ… ãƒ¢ãƒ‡ãƒ«ã¯å®Ÿç”¨ãƒ¬ãƒ™ãƒ«ã§æ±åŒ–")
    else:
        print(f"  ğŸ“ˆ æœªä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ã§ã‚‚æ”¹å–„å‚¾å‘ç¢ºèª")
        print(f"  æœ€å°æå¤±: {best_unseen_return:.2f}% (å‰å›: {previous_best:.2f}%)")
        print(f"  ğŸ”§ è¿½åŠ æœ€é©åŒ–ã§åç›ŠåŒ–å¯èƒ½æ€§é«˜")
    
    return unseen_results


if __name__ == "__main__":
    overfitting_check()