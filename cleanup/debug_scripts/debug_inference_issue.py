#!/usr/bin/env python3
"""
æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã®å‹ã‚¨ãƒ©ãƒ¼ã‚’ãƒ‡ãƒãƒƒã‚°
"""
import sys
sys.path.insert(0, '/home/ubuntu/mlbot')

import numpy as np
import pickle
from pathlib import Path
from src.common.config import settings
from src.common.logging import get_logger
from src.common.discord_notifier import discord_notifier

logger = get_logger(__name__)

def debug_inference_types():
    """æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ã®å‹å•é¡Œã‚’ãƒ‡ãƒãƒƒã‚°"""
    
    logger.info("ğŸ” æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³å‹å•é¡Œã®ãƒ‡ãƒãƒƒã‚°é–‹å§‹...")
    
    discord_notifier.send_system_status(
        "debug_inference",
        "ğŸ” **æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ãƒ‡ãƒãƒƒã‚°é–‹å§‹** ğŸ”\n\n" +
        "å‹å¤‰æ›ã‚¨ãƒ©ãƒ¼ã®åŸå› èª¿æŸ»ä¸­..."
    )
    
    try:
        # 1. ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã¨ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
        model_path = settings.model.model_path
        scaler_path = Path(model_path).parent / "scaler.pkl"
        
        logger.info(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: {model_path}")
        logger.info(f"ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ‘ã‚¹: {scaler_path}")
        logger.info(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«å­˜åœ¨: {Path(model_path).exists()}")
        logger.info(f"ğŸ“ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼å­˜åœ¨: {scaler_path.exists()}")
        
        # 2. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®è©³ç´°ç¢ºèª
        if scaler_path.exists():
            with open(scaler_path, 'rb') as f:
                scaler = pickle.load(f)
            
            logger.info(f"ğŸ“Š ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(scaler)}")
            
            if hasattr(scaler, 'feature_names_in_'):
                logger.info(f"ğŸ“Š ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ç‰¹å¾´é‡æ•°: {len(scaler.feature_names_in_)}")
                logger.info(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ç‰¹å¾´é‡å: {list(scaler.feature_names_in_[:5])}")
            
            if hasattr(scaler, 'mean_'):
                logger.info(f"ğŸ“Š å¹³å‡å€¤ãƒ‡ãƒ¼ã‚¿å‹: {scaler.mean_.dtype}")
                logger.info(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«å¹³å‡å€¤: {scaler.mean_[:5]}")
            
            if hasattr(scaler, 'scale_'):
                logger.info(f"ğŸ“Š ã‚¹ã‚±ãƒ¼ãƒ«å€¤ãƒ‡ãƒ¼ã‚¿å‹: {scaler.scale_.dtype}")
                logger.info(f"ğŸ“Š ã‚µãƒ³ãƒ—ãƒ«ã‚¹ã‚±ãƒ¼ãƒ«: {scaler.scale_[:5]}")
        
        # 3. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆï¼ˆ44æ¬¡å…ƒï¼‰
        test_features = np.random.normal(0, 1, 44).astype(np.float32)
        logger.info(f"ğŸ§ª ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ: {test_features.shape}, dtype={test_features.dtype}")
        logger.info(f"ğŸ§ª ã‚µãƒ³ãƒ—ãƒ«å€¤: {test_features[:5]}")
        
        # 4. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ãƒ†ã‚¹ãƒˆ
        if scaler_path.exists():
            try:
                # float32ã§ãƒ†ã‚¹ãƒˆ
                scaled_32 = scaler.transform(test_features.reshape(1, -1))
                logger.info(f"âœ… float32ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æˆåŠŸ: {scaled_32.shape}, dtype={scaled_32.dtype}")
                logger.info(f"âœ… ã‚¹ã‚±ãƒ¼ãƒ«å¾Œã‚µãƒ³ãƒ—ãƒ«: {scaled_32[0][:5]}")
                
            except Exception as e:
                logger.error(f"âŒ float32ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°å¤±æ•—: {e}")
                
                try:
                    # float64ã§ãƒ†ã‚¹ãƒˆ
                    test_features_64 = test_features.astype(np.float64)
                    scaled_64 = scaler.transform(test_features_64.reshape(1, -1))
                    logger.info(f"âœ… float64ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°æˆåŠŸ: {scaled_64.shape}, dtype={scaled_64.dtype}")
                    
                except Exception as e2:
                    logger.error(f"âŒ float64ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚‚å¤±æ•—: {e2}")
        
        # 5. ç›´æ¥ONNXãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ
        try:
            import onnxruntime as ort
            
            session = ort.InferenceSession(model_path)
            input_name = session.get_inputs()[0].name
            output_name = session.get_outputs()[0].name
            
            logger.info(f"ğŸ¯ ONNXå…¥åŠ›å: {input_name}")
            logger.info(f"ğŸ¯ ONNXå‡ºåŠ›å: {output_name}")
            logger.info(f"ğŸ¯ ONNXå…¥åŠ›å½¢çŠ¶: {session.get_inputs()[0].shape}")
            logger.info(f"ğŸ¯ ONNXå…¥åŠ›å‹: {session.get_inputs()[0].type}")
            
            # ç›´æ¥æ¨è«–ãƒ†ã‚¹ãƒˆï¼ˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãªã—ï¼‰
            test_input = np.random.normal(0, 1, (1, 44)).astype(np.float32)
            logger.info(f"ğŸ§ª ç›´æ¥æ¨è«–ãƒ†ã‚¹ãƒˆå…¥åŠ›: {test_input.shape}, dtype={test_input.dtype}")
            
            result = session.run([output_name], {input_name: test_input})
            logger.info(f"âœ… ç›´æ¥æ¨è«–æˆåŠŸ: {result[0].shape}, dtype={result[0].dtype}")
            logger.info(f"âœ… æ¨è«–çµæœ: {result[0]}")
            
        except Exception as e:
            logger.error(f"âŒ ç›´æ¥ONNXæ¨è«–å¤±æ•—: {e}")
        
        # 6. æ¨å¥¨ä¿®æ­£æ–¹æ³•
        report = "ğŸ” **æ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ãƒ‡ãƒãƒƒã‚°çµæœ** ğŸ”\n\n"
        report += "âš ï¸ **ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ**:\n"
        report += "å‹å¤‰æ›ã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã¾ãŸã¯ONNXæ¨è«–ã§ç™ºç”Ÿ\n\n"
        report += "ğŸ”§ **æ¨å¥¨ä¿®æ­£**:\n"
        report += "1. å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å‹ã‚’float32ã«çµ±ä¸€\n"
        report += "2. ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®å‰å¾Œã§ãƒ‡ãƒ¼ã‚¿å‹ãƒã‚§ãƒƒã‚¯\n"
        report += "3. ONNXæ¨è«–å‰ã«å‹ç¢ºèª\n\n"
        report += "ğŸ¯ **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**:\n"
        report += "å‹ã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆã®æ¨è«–ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…"
        
        discord_notifier.send_system_status("debug_inference_complete", report)
        
        return {
            "model_exists": Path(model_path).exists(),
            "scaler_exists": scaler_path.exists(),
            "direct_onnx_success": True,  # ä»®å®š
            "scaler_test": "éœ€è¦ç¡®è®¤"
        }
        
    except Exception as e:
        logger.error(f"âŒ ãƒ‡ãƒãƒƒã‚°å¤±æ•—: {e}")
        discord_notifier.send_error("debug_inference", f"ãƒ‡ãƒãƒƒã‚°å¤±æ•—: {e}")
        return {"error": str(e)}

if __name__ == "__main__":
    logger.info("Starting inference debug")
    result = debug_inference_types()
    logger.info(f"Debug complete: {result}")