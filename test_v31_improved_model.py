#!/usr/bin/env python3
"""
v3.1_improvedãƒ¢ãƒ‡ãƒ«ã®è¨ºæ–­ã¨ä¿®å¾©å¯èƒ½æ€§æ¤œè¨¼
- åˆ†é¡å™¨å•é¡Œã®è©³ç´°åˆ†æ
- å›å¸°å™¨ã¸ã®å¤‰æ›å¯èƒ½æ€§æ¤œè¨¼
- å®Ÿéš›ã®ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆèƒ½åŠ›ãƒ†ã‚¹ãƒˆ
"""

import sys
import asyncio
from pathlib import Path
import numpy as np
import onnx
import onnxruntime as ort

project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

async def test_v31_improved_model():
    """v3.1_improvedãƒ¢ãƒ‡ãƒ«ã®è©³ç´°è¨ºæ–­"""
    print("="*80)
    print("ğŸ”¬ v3.1_improved ãƒ¢ãƒ‡ãƒ«è¨ºæ–­ãƒ»ä¿®å¾©æ¤œè¨¼")
    print("="*80)
    
    model_dir = Path("models/v3.1_improved")
    
    try:
        # 1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        print("\n1ï¸âƒ£ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åˆ†æ...")
        
        import json
        with open(model_dir / "metadata.json", 'r') as f:
            metadata = json.load(f)
        
        print(f"âœ… v3.1_improved ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿:")
        print(f"   - ãƒ¢ãƒ‡ãƒ«å‹: {metadata.get('model_type', 'unknown')}")
        print(f"   - ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {metadata.get('model_version', 'unknown')}")
        print(f"   - ç‰¹å¾´é‡æ•°: {metadata.get('feature_count', 'unknown')}")
        print(f"   - è¨“ç·´æ—¥: {metadata.get('training_date', 'unknown')}")
        
        if 'performance' in metadata:
            perf = metadata['performance']
            print(f"   - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
            if 'best_auc' in perf:
                print(f"     * AUC: {perf['best_auc']:.3f}")
            if 'best_model' in perf:
                print(f"     * ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«: {perf['best_model']}")
        
        # 2. ONNXãƒ¢ãƒ‡ãƒ«æ§‹é€ åˆ†æ
        print("\n2ï¸âƒ£ ONNXãƒ¢ãƒ‡ãƒ«æ§‹é€ åˆ†æ...")
        
        model_path = model_dir / "model.onnx"
        model = onnx.load(str(model_path))
        
        # å…¥åŠ›æƒ…å ±
        input_info = model.graph.input[0]
        input_shape = [dim.dim_value for dim in input_info.type.tensor_type.shape.dim]
        input_type = input_info.type.tensor_type.elem_type
        
        print(f"âœ… ONNXæ§‹é€ :")
        print(f"   - å…¥åŠ›å½¢çŠ¶: {input_shape}")
        print(f"   - å…¥åŠ›å‹: {onnx.TensorProto.DataType.Name(input_type)}")
        
        # å‡ºåŠ›æƒ…å ±
        for i, output_info in enumerate(model.graph.output):
            output_shape = [dim.dim_value for dim in output_info.type.tensor_type.shape.dim]
            output_type = output_info.type.tensor_type.elem_type
            print(f"   - å‡ºåŠ›{i+1}: {output_shape}, å‹: {onnx.TensorProto.DataType.Name(output_type)}")
        
        # ãƒãƒ¼ãƒ‰åˆ†æ
        node_types = {}
        for node in model.graph.node:
            node_types[node.op_type] = node_types.get(node.op_type, 0) + 1
        
        print(f"   - ãƒãƒ¼ãƒ‰æ§‹æˆ: {dict(sorted(node_types.items()))}")
        
        # åˆ†é¡å™¨ã‹å›å¸°å™¨ã‹ã®åˆ¤å®š
        has_argmax = 'ArgMax' in node_types
        has_softmax = 'Softmax' in node_types
        has_sigmoid = 'Sigmoid' in node_types
        
        model_type = "åˆ†é¡å™¨" if (has_argmax or has_softmax) else "å›å¸°å™¨" if has_sigmoid else "ä¸æ˜"
        print(f"   - æ¨å®šå‹: {model_type}")
        
        # 3. å®Ÿéš›ã®æ¨è«–ãƒ†ã‚¹ãƒˆ
        print("\n3ï¸âƒ£ æ¨è«–ãƒ†ã‚¹ãƒˆ...")
        
        session = ort.InferenceSession(str(model_path))
        input_name = session.get_inputs()[0].name
        output_names = [output.name for output in session.get_outputs()]
        
        print(f"âœ… ONNXRuntimeæƒ…å ±:")
        print(f"   - å…¥åŠ›å: {input_name}")
        print(f"   - å‡ºåŠ›å: {output_names}")
        
        # ãƒ†ã‚¹ãƒˆç”¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ï¼ˆ44æ¬¡å…ƒæƒ³å®šï¼‰
        expected_features = 44
        test_inputs = [
            np.random.normal(0, 1, (1, expected_features)).astype(np.float32),  # æ¨™æº–æ­£è¦åˆ†å¸ƒ
            np.random.uniform(-1, 1, (1, expected_features)).astype(np.float32),  # å‡ç­‰åˆ†å¸ƒ
            np.zeros((1, expected_features), dtype=np.float32),  # ã‚¼ãƒ­å…¥åŠ›
            np.ones((1, expected_features), dtype=np.float32),   # 1å…¥åŠ›
            np.random.normal(0, 0.5, (1, expected_features)).astype(np.float32),  # å°ã•ãªåˆ†æ•£
        ]
        
        predictions = []
        
        for i, test_input in enumerate(test_inputs):
            try:
                outputs = session.run(output_names, {input_name: test_input})
                
                prediction_data = {
                    'input_id': i+1,
                    'input_stats': {
                        'min': float(test_input.min()),
                        'max': float(test_input.max()),
                        'mean': float(test_input.mean()),
                        'std': float(test_input.std())
                    },
                    'outputs': {}
                }
                
                for j, (output_name, output) in enumerate(zip(output_names, outputs)):
                    prediction_data['outputs'][output_name] = {
                        'shape': list(output.shape),
                        'dtype': str(output.dtype),
                        'values': output.tolist(),
                        'stats': {
                            'min': float(output.min()),
                            'max': float(output.max()),
                            'mean': float(output.mean()),
                            'std': float(output.std()) if output.size > 1 else 0.0
                        }
                    }
                
                predictions.append(prediction_data)
                
                print(f"   ãƒ†ã‚¹ãƒˆ{i+1}: ", end="")
                for output_name, output in zip(output_names, outputs):
                    print(f"{output_name}={output.flatten()[:3]} (å‹:{output.dtype})", end=" ")
                print()
                
            except Exception as e:
                print(f"   ãƒ†ã‚¹ãƒˆ{i+1}: ã‚¨ãƒ©ãƒ¼ - {e}")
        
        # 4. å•é¡Œè¨ºæ–­
        print("\n4ï¸âƒ£ å•é¡Œè¨ºæ–­...")
        
        if not predictions:
            print("âŒ å…¨ã¦ã®ãƒ†ã‚¹ãƒˆã§æ¨è«–å¤±æ•—")
            return False
        
        # å‡ºåŠ›ã®åˆ†æ
        first_prediction = predictions[0]
        main_output_name = output_names[0]
        main_output = first_prediction['outputs'][main_output_name]
        
        print(f"âœ… è¨ºæ–­çµæœ:")
        print(f"   - ä¸»å‡ºåŠ›å‹: {main_output['dtype']}")
        print(f"   - ä¸»å‡ºåŠ›å½¢çŠ¶: {main_output['shape']}")
        
        # åˆ†é¡å™¨å•é¡Œã®ç¢ºèª
        is_classifier_output = 'int' in main_output['dtype'].lower()
        
        if is_classifier_output:
            print("   ğŸš¨ ç¢ºèª: åˆ†é¡å™¨å‡ºåŠ›ï¼ˆintå‹ï¼‰")
            
            # å…¨ã¦ã®äºˆæ¸¬ãŒåŒã˜å€¤ã‹ãƒã‚§ãƒƒã‚¯
            all_predictions_same = True
            first_values = predictions[0]['outputs'][main_output_name]['values']
            
            for pred in predictions[1:]:
                if pred['outputs'][main_output_name]['values'] != first_values:
                    all_predictions_same = False
                    break
            
            if all_predictions_same:
                print("   âŒ å…¨äºˆæ¸¬ã§åŒã˜å€¤ â†’ å®Ÿè³ªçš„ã«æ©Ÿèƒ½ã—ã¦ã„ãªã„")
            else:
                print("   âœ… äºˆæ¸¬å€¤ã«å¤šæ§˜æ€§ã‚ã‚Š")
            
            # 5. ä¿®å¾©å¯èƒ½æ€§ã®æ¤œè¨¼
            print("\n5ï¸âƒ£ ä¿®å¾©å¯èƒ½æ€§æ¤œè¨¼...")
            
            # ONNXãƒ¢ãƒ‡ãƒ«ã®æœ€çµ‚å±¤ã‚’ç¢ºèª
            print("   æœ€çµ‚å±¤ãƒãƒ¼ãƒ‰åˆ†æ:")
            final_nodes = model.graph.node[-5:]  # æœ€å¾Œã®5ãƒãƒ¼ãƒ‰
            for node in final_nodes:
                print(f"     - {node.op_type}: {node.input} â†’ {node.output}")
            
            # ä¿®å¾©æˆ¦ç•¥ã®ææ¡ˆ
            print("\nğŸ“‹ ä¿®å¾©æˆ¦ç•¥:")
            
            if has_argmax:
                print("   1. ArgMaxãƒãƒ¼ãƒ‰é™¤å» â†’ ç¢ºç‡å€¤ç›´æ¥å–å¾—")
                print("   2. Softmaxå‡ºåŠ›ã‚’å›å¸°å€¤ã¨ã—ã¦è§£é‡ˆ")
                fix_difficulty = "ä¸­ç¨‹åº¦"
            elif 'int' in main_output['dtype'].lower():
                print("   1. æœ€çµ‚å±¤ã‚’floatå‡ºåŠ›ã«å¤‰æ›´")
                print("   2. é–¾å€¤é©ç”¨å‰ã®ç¢ºç‡å€¤å–å¾—")
                fix_difficulty = "å›°é›£"
            else:
                print("   1. å‡ºåŠ›ã®å¾Œå‡¦ç†ä¿®æ­£")
                fix_difficulty = "ç°¡å˜"
            
            print(f"   ä¿®å¾©é›£æ˜“åº¦: {fix_difficulty}")
            
            # 6. ä»£æ›¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ
            print("\n6ï¸âƒ£ ä»£æ›¿ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ...")
            
            # è¤‡æ•°å‡ºåŠ›ãŒã‚ã‚‹å ´åˆã®ç¢ºèª
            if len(output_names) > 1:
                print("   è¤‡æ•°å‡ºåŠ›æ¤œå‡º - ç¢ºç‡å‡ºåŠ›ã‚’æ¢ç´¢:")
                for name, pred in first_prediction['outputs'].items():
                    if 'float' in pred['dtype'].lower():
                        print(f"     âœ… {name}: floatå‹å‡ºåŠ›ç™ºè¦‹ (å€¤: {pred['values']})")
                        print("     â†’ ã“ã®å‡ºåŠ›ã‚’ä¿¡é ¼åº¦ã¨ã—ã¦ä½¿ç”¨å¯èƒ½")
                        return True
            
            # TreeEnsembleç‰¹æœ‰ã®å‡¦ç†
            if 'TreeEnsemble' in str(node_types):
                print("   TreeEnsembleæ¤œå‡º:")
                print("     - ç¢ºç‡å‡ºåŠ›ï¼ˆprobabilitesï¼‰ã®å­˜åœ¨ç¢ºèª")
                print("     - ãƒãƒ¼ãƒ‰å†æ§‹æˆã«ã‚ˆã‚‹å›å¸°åŒ–")
            
            print(f"\nğŸ“Š ç·åˆåˆ¤å®š:")
            if all_predictions_same:
                print("âŒ ä¿®å¾©ä¸æ¨å¥¨: äºˆæ¸¬å¤šæ§˜æ€§ãªã—")
                return False
            elif len(output_names) > 1:
                print("âœ… ä¿®å¾©å¯èƒ½: è¤‡æ•°å‡ºåŠ›ã‹ã‚‰ç¢ºç‡å€¤æŠ½å‡º")
                return True
            elif has_softmax or has_sigmoid:
                print("ğŸŸ¡ ä¿®å¾©å¯èƒ½: ç¢ºç‡å‡ºåŠ›ã‚’å›å¸°å€¤ã¨ã—ã¦ä½¿ç”¨")
                return True
            else:
                print("âŒ ä¿®å¾©å›°é›£: æ ¹æœ¬çš„ãªæ§‹é€ å¤‰æ›´ãŒå¿…è¦")
                return False
        
        else:
            print("   âœ… æ—¢ã«å›å¸°å™¨å‡ºåŠ›ï¼ˆfloatå‹ï¼‰")
            
            # äºˆæ¸¬å¤šæ§˜æ€§ã®ç¢ºèª
            all_values = []
            for pred in predictions:
                values = pred['outputs'][main_output_name]['values']
                all_values.extend(values)
            
            variance = np.var(all_values)
            
            if variance > 0.001:
                print(f"   âœ… äºˆæ¸¬å¤šæ§˜æ€§è‰¯å¥½ (åˆ†æ•£: {variance:.6f})")
                return True
            else:
                print(f"   âš ï¸ äºˆæ¸¬å¤šæ§˜æ€§ä¸è¶³ (åˆ†æ•£: {variance:.6f})")
                return False
        
    except Exception as e:
        print(f"âŒ è¨ºæ–­ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    try:
        result = asyncio.run(test_v31_improved_model())
        
        print("\n" + "="*80)
        if result:
            print("ğŸ‰ v3.1_improvedä¿®å¾©å¯èƒ½æ€§: âœ… é«˜ã„")
            print("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: ä¿®å¾©å®Ÿè£…ã«é€²ã‚€")
        else:
            print("âŒ v3.1_improvedä¿®å¾©å¯èƒ½æ€§: ä½ã„") 
            print("æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³: åˆ¥ã®ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’æ¤œè¨")
        print("="*80)
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    main()