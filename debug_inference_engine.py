#!/usr/bin/env python3
"""
InferenceEngineå®Œå…¨ãƒ‡ãƒãƒƒã‚° - å…¨ãƒ—ãƒ­ã‚»ã‚¹å¯è¦–åŒ–
"""

import sys
import os
import numpy as np
import json
import asyncio
from pathlib import Path

sys.path.append(os.path.dirname(os.path.abspath(__file__)))

async def complete_inference_debug():
    """InferenceEngineã®å®Œå…¨ãƒ‡ãƒãƒƒã‚°ã¨å…¨ãƒ—ãƒ­ã‚»ã‚¹å¯è¦–åŒ–"""
    
    print("ğŸ” InferenceEngineå®Œå…¨ãƒ‡ãƒãƒƒã‚°é–‹å§‹")
    print("=" * 80)
    
    # 1. ç’°å¢ƒç¢ºèª
    print("\n1. ç’°å¢ƒãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª")
    print("-" * 40)
    
    model_path = "models/v3.1_improved/model.onnx"
    scaler_path = "models/v3.1_improved/manual_scaler.json"
    
    print(f"Model exists: {os.path.exists(model_path)}")
    print(f"Scaler exists: {os.path.exists(scaler_path)}")
    
    if os.path.exists(model_path):
        model_size = os.path.getsize(model_path)
        print(f"Model size: {model_size:,} bytes")
    
    # 2. InferenceEngineã‚’ç›´æ¥ãƒ†ã‚¹ãƒˆ
    print("\n2. InferenceEngineç›´æ¥ãƒ†ã‚¹ãƒˆ")
    print("-" * 40)
    
    try:
        from src.ml_pipeline.inference_engine import InferenceEngine, InferenceConfig
        
        # è¨­å®šä½œæˆ
        config = InferenceConfig(
            model_path=model_path,
            enable_thompson_sampling=False,
            confidence_threshold=0.1,
            providers=["CPUExecutionProvider"]
        )
        
        # ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
        engine = InferenceEngine(config)
        print("âœ… InferenceEngineåˆæœŸåŒ–æˆåŠŸ")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        engine.load_model(model_path)
        print("âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿æˆåŠŸ")
        
        # 3. æŠ€è¡“çš„æŒ‡æ¨™ç”Ÿæˆ
        print("\n3. æŠ€è¡“çš„æŒ‡æ¨™ç”Ÿæˆ")
        print("-" * 40)
        
        from src.feature_hub.technical_indicators import TechnicalIndicatorEngine
        from src.ml_pipeline.feature_adapter_44 import FeatureAdapter44
        
        tech_engine = TechnicalIndicatorEngine()
        adapter = FeatureAdapter44()
        
        # è¤‡æ•°ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã§å±¥æ­´æ§‹ç¯‰
        prices = [
            (106000, 106500, 105500, 106250, 1000000),
            (106250, 106800, 105800, 106600, 1100000),
            (106600, 107000, 106200, 106800, 1200000),
            (106800, 107200, 106400, 107000, 1300000),
            (107000, 107500, 106700, 107200, 1400000),
        ]
        
        for i, (open_p, high, low, close, volume) in enumerate(prices):
            tech_engine.update_price_data("BTCUSDT", open_p, high, low, close, volume)
        
        features = tech_engine.get_latest_features("BTCUSDT")
        print(f"âœ… æŠ€è¡“çš„æŒ‡æ¨™ç”Ÿæˆ: {len(features)}å€‹")
        
        # é‡è¦ãªæŒ‡æ¨™å€¤ç¢ºèª
        key_features = ["returns", "vol_20", "rsi_14", "macd", "bb_position_20"]
        print("\né‡è¦æŒ‡æ¨™å€¤:")
        for key in key_features:
            value = features.get(key, "MISSING")
            print(f"  {key}: {value}")
        
        # 4. ç‰¹å¾´é‡å¤‰æ›
        print("\n4. ç‰¹å¾´é‡å¤‰æ›ï¼ˆ44æ¬¡å…ƒï¼‰")
        print("-" * 40)
        
        adapted = adapter.adapt(features)
        print(f"âœ… å¤‰æ›å®Œäº†: {adapted.shape}")
        print(f"éã‚¼ãƒ­å€¤: {np.count_nonzero(adapted)}/44")
        print(f"å€¤ç¯„å›²: [{np.min(adapted):.3f}, {np.max(adapted):.3f}]")
        
        # 5. InferenceEngineäºˆæ¸¬
        print("\n5. InferenceEngineäºˆæ¸¬ï¼ˆå®Œå…¨ãƒˆãƒ¬ãƒ¼ã‚¹ï¼‰")
        print("-" * 40)
        
        # Dictã§æ¸¡ã™ï¼ˆå®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ ã¨åŒã˜ï¼‰
        feature_dict = {f"feature_{i}": float(adapted[i]) for i in range(len(adapted))}
        
        print("ğŸ“¥ InferenceEngineã«é€ä¿¡...")
        print(f"  ç‰¹å¾´é‡ã‚¿ã‚¤ãƒ—: {type(feature_dict)}")
        print(f"  ç‰¹å¾´é‡æ•°: {len(feature_dict)}")
        
        # äºˆæ¸¬å®Ÿè¡Œ
        result = engine.predict(feature_dict, return_confidence=True, use_cache=False)
        
        print("ğŸ“¤ InferenceEngineè¿”ã‚Šå€¤ï¼ˆRAWï¼‰:")
        print(f"  è¿”ã‚Šå€¤ã‚¿ã‚¤ãƒ—: {type(result)}")
        print(f"  ã‚­ãƒ¼ä¸€è¦§: {list(result.keys()) if isinstance(result, dict) else 'NOT_DICT'}")
        
        for key, value in result.items():
            print(f"  {key}: {type(value)} = {value}")
        
        # 6. è¿”ã‚Šå€¤è©³ç´°åˆ†æ
        print("\n6. è¿”ã‚Šå€¤è©³ç´°åˆ†æ")
        print("-" * 40)
        
        # å„ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è©³ã—ãç¢ºèª
        predictions = result.get("predictions")
        raw_predictions = result.get("raw_predictions") 
        confidence_scores = result.get("confidence_scores")
        
        print(f"predictions: {type(predictions)} = {predictions}")
        print(f"raw_predictions: {type(raw_predictions)} = {raw_predictions}")
        print(f"confidence_scores: {type(confidence_scores)} = {confidence_scores}")
        
        # 7. æ‰‹å‹•ã§ONNXå®Ÿè¡Œï¼ˆæ¯”è¼ƒç”¨ï¼‰
        print("\n7. æ‰‹å‹•ONNXå®Ÿè¡Œï¼ˆæ¯”è¼ƒç”¨ï¼‰")
        print("-" * 40)
        
        import onnxruntime as ort
        
        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼èª­ã¿è¾¼ã¿
        with open(scaler_path, 'r') as f:
            scaler_data = json.load(f)
        
        means = np.array(scaler_data['means'])
        stds = np.array(scaler_data['stds'])
        
        # æ­£è¦åŒ–
        normalized = (adapted - means) / stds
        normalized = np.clip(normalized, -5, 5)
        
        print(f"æ­£è¦åŒ–å¾Œç¯„å›²: [{np.min(normalized):.3f}, {np.max(normalized):.3f}]")
        
        # ç›´æ¥ONNXå®Ÿè¡Œ
        session = ort.InferenceSession(model_path)
        input_name = session.get_inputs()[0].name
        output_name = session.get_outputs()[0].name
        
        onnx_result = session.run([output_name], {input_name: normalized.reshape(1, -1).astype(np.float32)})
        direct_output = onnx_result[0][0]
        
        print(f"ç›´æ¥ONNXå‡ºåŠ›: {direct_output}")
        print(f"å‡ºåŠ›ã‚¿ã‚¤ãƒ—: {type(direct_output)}")
        
        # 8. å•é¡Œè¨ºæ–­
        print("\n8. å•é¡Œè¨ºæ–­")
        print("-" * 40)
        
        issues = []
        
        if direct_output == 0:
            issues.append("ğŸš¨ ONNXç›´æ¥å®Ÿè¡Œã§0ãŒè¿”ã•ã‚Œã‚‹ - ãƒ¢ãƒ‡ãƒ«è‡ªä½“ã«å•é¡Œ")
        
        if predictions is None:
            issues.append("ğŸš¨ InferenceEngine.predictionsãŒNone")
        
        if raw_predictions is None:
            issues.append("ğŸš¨ InferenceEngine.raw_predictionsãŒNone") 
        
        if confidence_scores is None:
            issues.append("ğŸš¨ InferenceEngine.confidence_scoresãŒNone")
        
        # InferenceEngineã¨ç›´æ¥ONNXã®æ¯”è¼ƒ
        if raw_predictions is not None and len(raw_predictions) > 0:
            ie_output = raw_predictions[0]
            if abs(float(ie_output) - float(direct_output)) > 0.0001:
                issues.append(f"ğŸš¨ InferenceEngine({ie_output}) vs ç›´æ¥ONNX({direct_output})ã®ä¸ä¸€è‡´")
        
        if issues:
            print("âŒ ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ:")
            for issue in issues:
                print(f"  {issue}")
        else:
            print("âœ… å¤§ããªå•é¡Œã¯ç™ºè¦‹ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        # 9. ä¿®æ­£ææ¡ˆ
        print("\n9. ä¿®æ­£ææ¡ˆ")
        print("-" * 40)
        
        if direct_output == 0:
            print("ğŸ’¡ ãƒ¢ãƒ‡ãƒ«ä¿®å¾©æ–¹æ³•:")
            print("  - ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©¦ã™")
            print("  - ç‰¹å¾´é‡ã®æ­£è¦åŒ–æ–¹æ³•ã‚’ç¢ºèª")
            print("  - ãƒ¢ãƒ‡ãƒ«è¨“ç·´æ™‚ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèª")
        
        if raw_predictions is None or len(raw_predictions) == 0:
            print("ğŸ’¡ InferenceEngineä¿®å¾©æ–¹æ³•:")
            print("  - InferenceEngine.predictãƒ¡ã‚½ãƒƒãƒ‰ã®è¿”ã‚Šå€¤æ§‹é€ ã‚’ç¢ºèª")
            print("  - confidenceè¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¢ºèª")
        
        # 10. ä»£æ›¿æ¡ˆ
        print("\n10. ä»£æ›¿ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆï¼ˆæŠ€è¡“çš„æŒ‡æ¨™ãƒ™ãƒ¼ã‚¹ï¼‰")
        print("-" * 40)
        
        rsi = features.get("rsi_14", 50)
        macd = features.get("macd", 0)
        vol = features.get("vol_20", 0.01)
        bb_pos = features.get("bb_position_20", 0)
        
        print(f"RSI: {rsi:.2f}")
        print(f"MACD: {macd:.2f}")
        print(f"Volatility: {vol:.4f}")
        print(f"BB Position: {bb_pos:.2f}")
        
        # æŠ€è¡“çš„æŒ‡æ¨™ãƒ™ãƒ¼ã‚¹ã®ã‚·ã‚°ãƒŠãƒ«
        signal_strength = 0
        signal_direction = "HOLD"
        
        if rsi > 70:
            signal_strength += 0.3
            signal_direction = "SELL"
            print("  ğŸ”´ RSIéè²·ã„ â†’ SELLä¿¡å·")
        elif rsi < 30:
            signal_strength += 0.3 
            signal_direction = "BUY"
            print("  ğŸŸ¢ RSIéå£²ã‚Š â†’ BUYä¿¡å·")
        
        if abs(macd) > 50:
            signal_strength += 0.2
            if macd > 0 and signal_direction != "SELL":
                signal_direction = "BUY"
                print("  ğŸŸ¢ MACDå¼·æ°— â†’ BUYä¿¡å·")
            elif macd < 0 and signal_direction != "BUY":
                signal_direction = "SELL"
                print("  ğŸ”´ MACDå¼±æ°— â†’ SELLä¿¡å·")
        
        if vol > 0.02:
            signal_strength += 0.2
            print("  âš¡ é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ â†’ ä¿¡å·å¼·åº¦å‘ä¸Š")
        
        if signal_strength > 0.4:
            print(f"\nğŸ¯ æŠ€è¡“çš„æŒ‡æ¨™ã‚·ã‚°ãƒŠãƒ«: {signal_direction} (å¼·åº¦: {signal_strength:.2f})")
        else:
            print(f"\nâ¸ï¸  æŠ€è¡“çš„æŒ‡æ¨™ã‚·ã‚°ãƒŠãƒ«: {signal_direction} (å¼·åº¦: {signal_strength:.2f} - å¼±ã„)")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 80)
    print("å®Œå…¨ãƒ‡ãƒãƒƒã‚°çµ‚äº†")

if __name__ == "__main__":
    asyncio.run(complete_inference_debug())